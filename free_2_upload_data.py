"""
Bible AI ì• í”Œë¦¬ì¼€ì´ì…˜ ë°ì´í„° ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ (ë¬´ë£Œ ëª¨ë¸ ë²„ì „)

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Bible AI Q&A ë°ì´í„°ë¥¼ Pinecone ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.
sentence-transformers ë¬´ë£Œ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ API ë¹„ìš© ì—†ì´ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. CSV íŒŒì¼ ë°ì´í„° ì½ê¸° ë° ì „ì²˜ë¦¬ (HTML íƒœê·¸ ì œê±°)
2. ë¬´ë£Œ sentence-transformers ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„±
3. ì§ˆë¬¸ ìë™ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
4. Pinecone ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë°°ì¹˜ ì—…ë¡œë“œ
5. ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§ ë° í†µê³„ ì œê³µ

ë°ì´í„° êµ¬ì¡°:
- seq: ê³ ìœ  ì‹ë³„ì
- contents: ì§ˆë¬¸ ë‚´ìš© 
- reply_contents: ë‹µë³€ ë‚´ìš©
"""

import os # íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬ íŒŒì´ì¬ ëª¨ë“ˆ
import sys # ì‹œìŠ¤í…œ ê´€ë ¨ ì‘ì—… íŒŒì´ì¬ ëª¨ë“ˆ
import pandas as pd # ë°ì´í„° ì²˜ë¦¬ íŒŒì´ì¬ ëª¨ë“ˆ
from dotenv import load_dotenv # í™˜ê²½ë³€ìˆ˜ ì²˜ë¦¬ íŒŒì´ì¬ ëª¨ë“ˆ
from pinecone import Pinecone # Pinecone í´ë¼ì´ì–¸íŠ¸ íŒŒì´ì¬ ëª¨ë“ˆ
import time # ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
import re # ì •ê·œì‹ ê²€ì‚¬ íŒŒì´ì¬ ëª¨ë“ˆ
from datetime import datetime # ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
from sentence_transformers import SentenceTransformer # ì„ë² ë”© ëª¨ë¸ íŒŒì´ì¬ ëª¨ë“ˆ
import html # HTML íƒœê·¸ ì²˜ë¦¬ íŒŒì´ì¬ ëª¨ë“ˆ
from typing import Optional, List, Dict, Any # íƒ€ì… íŒíŠ¸ íŒŒì´ì¬ ëª¨ë“ˆ
import unicodedata # ìœ ë‹ˆì½”ë“œ ë¬¸ì ì²˜ë¦¬
import logging # ë¡œê·¸ ê¸°ë¡ íŒŒì´ì¬ ëª¨ë“ˆ
import openai # OpenAI API í´ë¼ì´ì–¸íŠ¸

# ====== ì„¤ì • ìƒìˆ˜ ======
MODEL_NAME = 'text-embedding-3-small'
INDEX_NAME = "bible-app-support-1536-openai"
DATA_FILE = "data_2025.csv"
EMBEDDING_DIMENSION = 1536
DEFAULT_BATCH_SIZE = 20
MAX_TEXT_LENGTH = 8000
MAX_METADATA_LENGTH = 1000

# ë„ë©”ì¸ íŠ¹í™” ì¤‘ìš” í‚¤ì›Œë“œ (ê°€ì¤‘ì¹˜ë¥¼ ë†’ì¼ ë‹¨ì–´ë“¤)
DOMAIN_KEYWORDS = set([
    'ì„±ê²½', 'ì°¬ì†¡ê°€', 'êµ¬ì ˆ', 'ë§ì”€', 'ê¸°ë„', 'ì˜ˆë°°', 'ì°¬ì–‘', 'ë¬µìƒ', 'íí‹°',
    'ì˜¤ë¥˜', 'ì˜¤íƒ€', 'ë²„ê·¸', 'ì—ëŸ¬', 'ë¬¸ì œ', 'ìˆ˜ì •', 'ê°œì„ ', 'ìš”ì²­',
    'ê²°ì œ', 'êµ¬ë…', 'í›„ì›', 'í™˜ë¶ˆ', 'ì·¨ì†Œ', 'í•´ì§€',
    'ë‹¤ìš´ë¡œë“œ', 'ì„¤ì¹˜', 'ì—…ë°ì´íŠ¸', 'ë²„ì „', 'ì•±'
])

# ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ì •ì˜ (ê° ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜)
CATEGORY_KEYWORDS = {
    'í›„ì›/í•´ì§€': [
        'í›„ì›', 'ê¸°ë¶€', 'ê²°ì œ', 'êµ¬ë…', 'í•´ì§€', 'ì·¨ì†Œ', 'í™˜ë¶ˆ', 'ìš”ê¸ˆ', 'ìœ ë£Œ', 
        'í”„ë¦¬ë¯¸ì—„', 'ì •ê¸°ê²°ì œ', 'ìë™ê²°ì œ', 'ê²°ì œìˆ˜ë‹¨', 'ì¹´ë“œ', 'ê³„ì¢Œ', 'ì†¡ê¸ˆ'
    ],
    'ì„±ê²½ í†µë…(ì½ê¸°,ë“£ê¸°,ë…¹ìŒ)': [
        'í†µë…', 'ì½ê¸°', 'ë“£ê¸°', 'ë…¹ìŒ', 'ì„±ê²½ì½ê¸°', 'ë§ì”€ë“£ê¸°', 'ìŒì„±', 'ì˜¤ë””ì˜¤',
        'ë‚­ë…', 'ë…ì„œ', 'ì„±ê²½ê³µë¶€', 'ë¬µìƒ', 'íí‹°', 'qt', 'ìŒì„±ë…¹ìŒ', 'ì¬ìƒ',
        'ë…ì„œê³„íš', 'ì„±ê²½ì „ì²´', 'êµ¬ì•½', 'ì‹ ì•½', 'ì„±ê²½ë“£ê¸°'
    ],
    'ì„±ê²½ë‚­ë… ë ˆì´ìŠ¤': [
        'ë ˆì´ìŠ¤', 'ê²½ìŸ', 'ëŒ€íšŒ', 'ì°¸ì—¬', 'ìˆœìœ„', 'ë­í‚¹', 'ê²½ì£¼', 'ë„ì „',
        'ì„±ê²½ë‚­ë…ë ˆì´ìŠ¤', 'ë‚­ë…ëŒ€íšŒ', 'ë‚­ë…ê²½ìŸ', 'ì„±ê²½ì•”ì†¡'
    ],
    'ê°œì„ /ì œì•ˆ': [
        'ê°œì„ ', 'ì œì•ˆ', 'ê±´ì˜', 'ìš”ì²­', 'ë°”ëŒ', 'ê¸°ëŠ¥ì¶”ê°€', 'ìƒˆê¸°ëŠ¥', 'ì—…ë°ì´íŠ¸',
        'ê°œë°œ', 'ì¶”ê°€í•´ì£¼ì„¸ìš”', 'ë§Œë“¤ì–´ì£¼ì„¸ìš”', 'ë„£ì–´ì£¼ì„¸ìš”', 'ê°œì„ í•´ì£¼ì„¸ìš”',
        'ë”ì¢‹ê²Œ', 'í¸ë¦¬í•˜ê²Œ', 'ì—…ê·¸ë ˆì´ë“œ'
    ],
    'ì˜¤ë¥˜/ì¥ì• ': [
        'ì˜¤ë¥˜', 'ì—ëŸ¬', 'ë²„ê·¸', 'ë¬¸ì œ', 'ê³ ì¥', 'ì¥ì• ', 'ì•ˆë¨', 'ì•ˆë˜ìš”', 
        'ì‘ë™ì•ˆí•¨', 'ì‹¤í–‰ì•ˆë¨', 'ë©ˆì¶¤', 'ì¢…ë£Œ', 'ëŠë¦¼', 'ëŠë ¤', 'ëŠê¹€',
        'ë¡œë”©', 'ì ‘ì†ë¶ˆê°€', 'ì—°ê²°ì•ˆë¨', 'ë‹¤ìš´', 'í¬ë˜ì‹œ', 'íŠ•ê¹€'
    ],
    'ë¶ˆë§Œ': [
        'ë¶ˆë§Œ', 'ë¶ˆí¸', 'ì§œì¦', 'í™”ë‚¨', 'ì‹«ì–´', 'ë§ˆìŒì—ì•ˆë“¬', 'ë³„ë¡œ',
        'ì‹¤ë§', 'ë¶ˆì¾Œ', 'ê¸°ë¶„ë‚˜ì¨', 'ì„œë¹„ìŠ¤ë‚˜ì¨', 'ë‹µë‹µ', 'ì†ìƒ'
    ],
    'ì˜¤íƒˆìì œë³´': [
        'ì˜¤íƒˆì', 'ì˜¤íƒ€', 'ì˜¤ì—­', 'ë²ˆì—­ì˜¤ë¥˜', 'ë²ˆì—­í‹€ë¦¼', 'í‹€ë ¸', 'ì˜ëª»',
        'ë‚´ìš©ì˜¤ë¥˜', 'ì„±ê²½ì˜¤ë¥˜', 'êµ¬ì ˆí‹€ë¦¼', 'ë³¸ë¬¸í‹€ë¦¼', 'ìˆ˜ì •', 'ì •ì •',
        'ì˜ëª»ëœë‚´ìš©', 'ì˜¤ë¥˜ì œë³´', 'ë‚´ìš©ì˜ëª»'
    ]
}

# â˜… í•¨ìˆ˜ 1. í•„ìš”í•œ ì„œë¹„ìŠ¤ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
# Returns:
# tuple: (Pinecone í´ë¼ì´ì–¸íŠ¸, ì¸ë±ìŠ¤, OpenAI í´ë¼ì´ì–¸íŠ¸) 
# Raises:
# SystemExit: ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ
def initialize_services() -> tuple[Pinecone, Any, Any]:
    print(" í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ì¤‘...")
    load_dotenv()
    
    # API í‚¤ í™•ì¸
    pinecone_api_key = os.getenv('PINECONE_API_KEY')
    openai_api_key = os.getenv('OPENAI_API_KEY')
    
    if not pinecone_api_key:
        print("âŒ PINECONE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ .env íŒŒì¼ì— PINECONE_API_KEY=your_api_keyë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        sys.exit(1)
    
    if not openai_api_key:
        print("âŒ OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ .env íŒŒì¼ì— OPENAI_API_KEY=your_api_keyë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        sys.exit(1)
    
    print("âœ“ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ!")
    
    # Pinecone ì´ˆê¸°í™”
    print(" Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")
    try:
        pc = Pinecone(api_key=pinecone_api_key)
        index = pc.Index(INDEX_NAME)
        print("âœ“ Pinecone ì—°ê²° ì™„ë£Œ!")
    except Exception as e:
        print(f"âŒ Pinecone ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print(" API í‚¤ì™€ ì¸ë±ìŠ¤ ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”.")
        sys.exit(1)
    
    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì•ˆì „í•œ ë°©ì‹)
    print(f" OpenAI {MODEL_NAME} ëª¨ë¸ ì¤€ë¹„ ì¤‘...")
    try:
        # ë°©ë²• 1: í™˜ê²½ë³€ìˆ˜ ì„¤ì • í›„ ê¸°ë³¸ ì´ˆê¸°í™”
        os.environ['OPENAI_API_KEY'] = openai_api_key
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ê¸°ë³¸ ì„¤ì •ë§Œ ì‚¬ìš©)
        openai_client = openai.OpenAI()
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í˜¸ì¶œë¡œ ì—°ê²° í™•ì¸
        test_response = openai_client.embeddings.create(
            model=MODEL_NAME,
            input="í…ŒìŠ¤íŠ¸"
        )
        
        print("âœ“ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ë° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"âœ“ í…ŒìŠ¤íŠ¸ ì„ë² ë”© ì°¨ì›: {len(test_response.data[0].embedding)}")
        
    except Exception as e:
        print(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ OpenAI API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        print(f"ë””ë²„ê·¸: API í‚¤ ê¸¸ì´: {len(openai_api_key) if openai_api_key else 0}")
        
        # ëŒ€ì•ˆ ë°©ë²• ì‹œë„
        try:
            print(" ëŒ€ì•ˆ ë°©ë²•ìœ¼ë¡œ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹œë„...")
            openai_client = openai.OpenAI(api_key=openai_api_key)
            print("âœ“ ëŒ€ì•ˆ ë°©ë²•ìœ¼ë¡œ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ!")
        except Exception as e2:
            print(f"âŒ ëŒ€ì•ˆ ë°©ë²•ë„ ì‹¤íŒ¨: {e2}")
            print("ğŸ’¡ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì„¤ì¹˜í•´ë³´ì„¸ìš”.")
            print(" pip install openai==1.3.0")
            sys.exit(1)
    
    return pc, index, openai_client

# â˜… í•¨ìˆ˜ 2. í†µí•© í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜
# Args:
#     text (str): ì „ì²˜ë¦¬í•  ì›ë³¸ í…ìŠ¤íŠ¸
#     for_metadata (bool): ë©”íƒ€ë°ì´í„°ìš© ì „ì²˜ë¦¬ ì—¬ë¶€      
# Returns:
#     str: ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸
def preprocess_text(text: str, for_metadata: bool = False) -> str:

    if not text or pd.isna(text):
        return ""
    
    # 1. ê¸°ë³¸ ì „ì²˜ë¦¬
    text = str(text)
    text = html.unescape(text)
    
    # 2. HTML íƒœê·¸ ì œê±°
    text = re.sub(r'<br\s*/?>', '\n', text, flags=re.IGNORECASE)
    text = re.sub(r'</p>', '\n', text, flags=re.IGNORECASE)
    text = re.sub(r'<p[^>]*>', '\n', text, flags=re.IGNORECASE)
    text = re.sub(r'<li[^>]*>', '\n- ', text, flags=re.IGNORECASE)
    text = re.sub(r'</li>', '', text, flags=re.IGNORECASE)
    text = re.sub(r'<(strong|b)[^>]*>', '**', text, flags=re.IGNORECASE)
    text = re.sub(r'</(strong|b)>', '**', text, flags=re.IGNORECASE)
    text = re.sub(r'<[^>]+>', '', text)
    
    # 3. ìœ ë‹ˆì½”ë“œ ì •ê·œí™”
    text = unicodedata.normalize('NFC', text)
    text = re.sub(r'[\u00A0\u2000-\u200B\u202F\u205F\u3000\uFEFF]', ' ', text)
    
    # 4. ë…¸ì´ì¦ˆ ì œê±°
    text = re.sub(r'([!?.]){2,}', r'\1', text)
    text = re.sub(r'([ã„±-ã…ã…-ã…£])\1{3,}', r'\1\1', text)
    text = re.sub(r'https?://\S+|www\.\S+', '[URL]', text)
    text = re.sub(r'\S+@\S+\.\S+', '[EMAIL]', text)
    text = re.sub(r'\d{2,4}-\d{3,4}-\d{4}', '[PHONE]', text)
    
    # 5. ê³µë°± ì •ë¦¬
    if for_metadata:
        # ë©”íƒ€ë°ì´í„°ìš©: ì¤„ë°”ê¿ˆ ìœ ì§€
        text = re.sub(r'\r\n|\r', '\n', text)
        text = re.sub(r'\n{3,}', '\n\n', text)
        text = re.sub(r'[ \t]+', ' ', text)
        lines = [line.strip() for line in text.split('\n')]
        text = '\n'.join(line for line in lines if line)
    else:
        # ì„ë² ë”©ìš©: ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ
        text = re.sub(r'\r\n|\r|\n', ' ', text)
        text = text.replace('\t', ' ')
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'\s+([.,!?;:])', r'\1', text)
        text = re.sub(r'([.,!?;:])\s+', r'\1 ', text)
        text = re.sub(r'\(\s+', '(', text)
        text = re.sub(r'\s+\)', ')', text)
    
    text = text.strip()
    
    # 6. ê¸¸ì´ ì œí•œ
    max_length = MAX_METADATA_LENGTH if for_metadata else MAX_TEXT_LENGTH
    if len(text) > max_length:
        if for_metadata:
            text = text[:max_length-3] + "..."
        else:
            front_len = int(max_length * 0.6)
            back_len = max_length - front_len
            text = text[:front_len] + " ... " + text[-back_len:]
            print(f"âš ï¸ í…ìŠ¤íŠ¸ê°€ {max_length}ìë¡œ ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return text

# â˜… í•¨ìˆ˜ 3. ë„ë©”ì¸ íŠ¹í™” í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜
# Args:
#     text (str): í‚¤ì›Œë“œ ì¶”ì¶œí•  í…ìŠ¤íŠ¸
# Returns:
#     List[str]: ì¶”ì¶œëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
def extract_keywords(text: str) -> List[str]:
    keywords = []
    
    # ì„±ê²½ êµ¬ì ˆ íŒ¨í„´ ì¶”ì¶œ
    bible_verses = re.findall(r'[ê°€-í£]+[ì„œë³µìŒê¸°ë¡ìƒí•˜ì „í›„í¸]+\s*\d+[ì¥ì ˆ:]+\s*\d*', text)
    keywords.extend(bible_verses) # extend: ë¦¬ìŠ¤íŠ¸ì— ìš”ì†Œë¥¼ ì¶”ê°€í•˜ëŠ” ë‚´ì¥ ë©”ì„œë“œ (ë°˜ë³µ ê°€ëŠ¥í•œ ê°ì²´ì˜ ìš”ì†Œë¥¼ í•˜ë‚˜ì”© êº¼ë‚´ì„œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€)
    
    # ì°¬ì†¡ê°€ ë²ˆí˜¸ ì¶”ì¶œ
    hymn_numbers = re.findall(r'ì°¬ì†¡ê°€?\s*\d+ì¥?', text) # findall: ì •ê·œì‹ íŒ¨í„´ê³¼ ì¼ì¹˜í•˜ëŠ” ëª¨ë“  ë¶€ë¶„ì„ ì°¾ì•„ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ëŠ” ë‚´ì¥ ë©”ì„œë“œ
    keywords.extend(hymn_numbers) 
    
    # ë„ë©”ì¸ í‚¤ì›Œë“œ ì¶”ì¶œ
    for keyword in DOMAIN_KEYWORDS:
        if keyword in text:
            keywords.append(keyword) # append: ë¦¬ìŠ¤íŠ¸ ëì— ë§¤ê°œë³€ìˆ˜ìˆ˜ë¥¼ ì¶”ê°€í•˜ëŠ” ë‚´ì¥ ë©”ì„œë“œ
    
    return keywords

# â˜… í•¨ìˆ˜ 4. ì„ë² ë”© ìƒì„± í•¨ìˆ˜
# í…ìŠ¤íŠ¸ë¥¼ OpenAI text-embedding-3-small ëª¨ë¸ë¡œ 1536ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
# Args:
#     text (str): ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•  í…ìŠ¤íŠ¸
#     openai_client (Any): OpenAI í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤
#     retry_count (int): ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜       
# Returns:
#     Optional[List[float]]: ì„±ê³µ ì‹œ 1536ì°¨ì› ì„ë² ë”© ë²¡í„°, ì‹¤íŒ¨ ì‹œ None
def create_embedding(text: str, openai_client: Any, retry_count: int = 3) -> Optional[List[float]]:

    if not text or not text.strip():
        print("âš ï¸ ë¹ˆ í…ìŠ¤íŠ¸ë¡œ ì¸í•´ ì„ë² ë”© ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None
    
    # í‚¤ì›Œë“œ ê°•ì¡° ì²˜ë¦¬
    keywords = extract_keywords(text)
    if keywords:
        keyword_str = ' '.join(keywords[:3])
        text = f"{keyword_str} {text}"
    
    # ì¬ì‹œë„ ë¡œì§ì„ í¬í•¨í•œ ì„ë² ë”© ìƒì„±
    for attempt in range(retry_count):
        try:
            # OpenAI text-embedding-3-small ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„±
            response = openai_client.embeddings.create(
                model=MODEL_NAME,
                input=text
            )
            
            embedding_list = response.data[0].embedding
            
            # ì°¨ì› ê²€ì¦
            if len(embedding_list) != EMBEDDING_DIMENSION:
                print(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì„ë² ë”© ì°¨ì›: {len(embedding_list)} (ì˜ˆìƒ: {EMBEDDING_DIMENSION})")
            
            return embedding_list
            
        except Exception as e:
            print(f"  ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{retry_count}): {e}")
            
            if attempt < retry_count - 1:
                wait_time = 2 ** attempt
                print(f"  {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                time.sleep(wait_time)
            else:
                print("  ëª¨ë“  ì¬ì‹œë„ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return None

# â˜… í•¨ìˆ˜ 5. ì§ˆë¬¸ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
# Args:
#     question (str): ë¶„ë¥˜í•  ì§ˆë¬¸ í…ìŠ¤íŠ¸
# Returns:
#     str: ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬ëª…
def categorize_question(question: str) -> str:
    if not question or not question.strip():
        return 'ì‚¬ìš© ë¬¸ì˜(ê¸°íƒ€)'
    
    question_lower = question.lower()
    
    # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ í‚¤ì›Œë“œ ë§¤ì¹­ ê²€ì‚¬
    for category, keywords in CATEGORY_KEYWORDS.items():
        if any(keyword in question_lower for keyword in keywords):
            return category
    
    return 'ì‚¬ìš© ë¬¸ì˜(ê¸°íƒ€)'

# â˜… í•¨ìˆ˜ 6. CSV íŒŒì¼ì„ ë‹¤ì–‘í•œ ì¸ì½”ë”©ìœ¼ë¡œ ì‹œë„í•˜ì—¬ ì•ˆì „í•˜ê²Œ ë¡œë“œí•©ë‹ˆë‹¤.
# Args:
#     file_path (str): ë¡œë“œí•  CSV íŒŒì¼ ê²½ë¡œ
# Returns:
#     pd.DataFrame: ë¡œë“œëœ ë°ì´í„°í”„ë ˆì„
# Raises:
#     Exception: ëª¨ë“  ì¸ì½”ë”© ì‹œë„ê°€ ì‹¤íŒ¨í•œ ê²½ìš°
def load_csv_data(file_path: str) -> pd.DataFrame:
    print(f"\nğŸ“– '{file_path}' íŒŒì¼ ì½ëŠ” ì¤‘...")
    
    encodings = ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr', 'latin1']
    
    for encoding in encodings:
        try:
            df = pd.read_csv(file_path, encoding=encoding)
            print(f"âœ“ ì¸ì½”ë”© '{encoding}'ìœ¼ë¡œ íŒŒì¼ ì½ê¸° ì„±ê³µ")
            print(f"âœ“ ì´ {len(df)}ê°œ í–‰ ë°œê²¬")
            print(f"âœ“ ì»¬ëŸ¼: {df.columns.tolist()}")
            return df
            
        except UnicodeDecodeError:
            print(f"  ì¸ì½”ë”© '{encoding}' ì‹¤íŒ¨, ë‹¤ìŒ ì¸ì½”ë”© ì‹œë„...")
            continue
        except Exception as e:
            print(f"  ì¸ì½”ë”© '{encoding}' ì˜¤ë¥˜: {e}")
            continue
    
    raise Exception(f"'{file_path}' íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì´ ì¡´ì¬í•˜ê³  ì˜¬ë°”ë¥¸ CSV í˜•ì‹ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")

# â˜… í•¨ìˆ˜ 7. CSV íŒŒì¼ì˜ Q&A ë°ì´í„°ë¥¼ Pinecone ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.
# Args:
#     batch_size (int): í•œ ë²ˆì— ì—…ë¡œë“œí•  ë²¡í„° ìˆ˜
#     max_items (Optional[int]): í…ŒìŠ¤íŠ¸ìš© ìµœëŒ€ ì•„ì´í…œ ìˆ˜ ì œí•œ
# Returns:
#     None: ì—…ë¡œë“œ ì™„ë£Œ í›„ ë°˜í™˜ ê°’ ì—†ìŒ
def upload_bible_data(batch_size: int = DEFAULT_BATCH_SIZE, max_items: Optional[int] = None) -> None:
    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    pc, index, openai_client = initialize_services()
    
    print("=" * 60)
    print("ğŸš€ Bible AI Q&A ë°ì´í„° ì—…ë¡œë“œ ì‹œì‘")
    print(f"ğŸ“ íŒŒì¼: {DATA_FILE}")
    print(f"ğŸ¤– ëª¨ë¸: {MODEL_NAME}")
    print(f"ğŸ“ ì°¨ì›: {EMBEDDING_DIMENSION}ì°¨ì›")
    print(f"ğŸ’° OpenAI ìœ ë£Œ ëª¨ë¸ ì‚¬ìš© - ë” ì •í™•í•œ ì˜ë¯¸ ê²€ìƒ‰!")
    print("=" * 60)
    
    # ë°ì´í„° ì½ê¸°
    try:
        df = load_csv_data(DATA_FILE)
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    print("\nğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
    
    if not df.empty:
        print("\nğŸ“ ì „ì²˜ë¦¬ ì „ ìƒ˜í”Œ:")
        sample_reply = df['reply_contents'].iloc[0]
        print(f"ì›ë³¸: {sample_reply[:150]}...")
        
        # ì „ì²˜ë¦¬ ì ìš©
        df['contents'] = df['contents'].apply(lambda x: preprocess_text(x, for_metadata=False))
        df['reply_contents'] = df['reply_contents'].apply(lambda x: preprocess_text(x, for_metadata=False))
        
        print("\nğŸ“ ì „ì²˜ë¦¬ í›„ ìƒ˜í”Œ:")
        cleaned_reply = df['reply_contents'].iloc[0]
        print(f"ì •ë¦¬ë¨: {cleaned_reply[:150]}...")
    
    # ë¹ˆ ê°’ ì œê±°
    df = df[(df['contents'] != '') & (df['reply_contents'] != '')]
    
    # í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ì œí•œ
    if max_items and len(df) > max_items:
        df = df.head(max_items)
        print(f"âœ“ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ {max_items}ê°œë¡œ ì œí•œ")
    
    print(f"âœ“ ìœ íš¨í•œ ë°ì´í„°: {len(df)}ê°œ")
    
    # ì—…ë¡œë“œ ì‹œì‘
    print(f"\nğŸ“¤ Pinecone ì—…ë¡œë“œ ì‹œì‘...")
    print(f"ë°°ì¹˜ í¬ê¸°: {batch_size}ê°œ")
    
    vectors_to_upsert = []
    success_count = 0
    failed_count = 0
    start_time = datetime.now()
    
    for idx, row in df.iterrows():
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        if idx % 10 == 0:
            elapsed_time = (datetime.now() - start_time).total_seconds()
            if idx > 0:
                avg_time_per_item = elapsed_time / idx
                remaining_items = len(df) - idx
                estimated_remaining = avg_time_per_item * remaining_items
                print(f"\nì§„í–‰: {idx}/{len(df)} ({idx/len(df)*100:.1f}%) | "
                      f"ì„±ê³µ: {success_count} | ì‹¤íŒ¨: {failed_count} | "
                      f"ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {estimated_remaining/60:.1f}ë¶„")
        
        # ì§ˆë¬¸ ë²¡í„°í™” (OpenAI í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©)
        embedding = create_embedding(row['contents'], openai_client)
        
        if embedding is None:
            failed_count += 1
            continue
        
        # ì¹´í…Œê³ ë¦¬ ìë™ ë¶„ë¥˜
        category = categorize_question(row['contents'])
        
        # ë©”íƒ€ë°ì´í„° êµ¬ì„± (ë©”íƒ€ë°ì´í„°ìš© ì „ì²˜ë¦¬ ì ìš©)
        metadata = {
            "seq": int(row['seq']),
            "question": preprocess_text(row['contents'], for_metadata=True),
            "answer": preprocess_text(row['reply_contents'], for_metadata=True),
            "category": category,
            "source": "data_2025_sample_free"
        }
        
        # ê³ ìœ  ID ìƒì„±
        unique_id = f"qa_free_{row['seq']}"
        
        # ë²¡í„° ë°ì´í„° êµ¬ì„±
        vectors_to_upsert.append({
            "id": unique_id,
            "values": embedding,
            "metadata": metadata
        })
        
        # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ ì—…ë¡œë“œ
        if len(vectors_to_upsert) >= batch_size:
            try:
                index.upsert(vectors=vectors_to_upsert)
                success_count += len(vectors_to_upsert)
                print(f"  âœ“ {len(vectors_to_upsert)}ê°œ ë²¡í„° ì—…ë¡œë“œ ì™„ë£Œ")
                vectors_to_upsert = []
                time.sleep(1)  # API ì œí•œ ë°©ì§€
            except Exception as e:
                print(f"  âŒ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
                failed_count += len(vectors_to_upsert)
                vectors_to_upsert = []
    
    # ë‚¨ì€ ë²¡í„° ì—…ë¡œë“œ
    if vectors_to_upsert:
        try:
            index.upsert(vectors=vectors_to_upsert)
            success_count += len(vectors_to_upsert)
            print(f"  âœ“ ë§ˆì§€ë§‰ {len(vectors_to_upsert)}ê°œ ë²¡í„° ì—…ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"  âŒ ë§ˆì§€ë§‰ ë°°ì¹˜ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
            failed_count += len(vectors_to_upsert)
    
    # ìµœì¢… í†µê³„
    total_time = (datetime.now() - start_time).total_seconds()
    print("\n" + "=" * 60)
    print("ğŸ“Š ì—…ë¡œë“œ ì™„ë£Œ í†µê³„")
    print("=" * 60)
    print(f"âœ“ ì„±ê³µ: {success_count}ê°œ")
    print(f"âœ— ì‹¤íŒ¨: {failed_count}ê°œ")
    print(f"â± ì´ ì†Œìš” ì‹œê°„: {total_time/60:.1f}ë¶„")
    
    if total_time > 0:
        print(f"ğŸ’¾ í‰ê·  ì²˜ë¦¬ ì†ë„: {success_count/(total_time/60):.1f}ê°œ/ë¶„")
    
    # Pinecone ì¸ë±ìŠ¤ í†µê³„
    try:
        print("\nğŸ“ˆ Pinecone ì¸ë±ìŠ¤ ìƒíƒœ:")
        stats = index.describe_index_stats()
        print(f"ì´ ë²¡í„° ìˆ˜: {stats['total_vector_count']}")
    except Exception as e:
        print(f"ğŸ“ˆ ì¸ë±ìŠ¤ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    print(f"\nâœ… {DATA_FILE} ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("ğŸ’° OpenAI ìœ ë£Œ ëª¨ë¸ ì‚¬ìš©ìœ¼ë¡œ API ë¹„ìš© ì—†ìŒ!")

def main() -> None:
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜: ì‚¬ìš©ì í™•ì¸ í›„ ë°ì´í„° ì—…ë¡œë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    print("=" * 60)
    print("ğŸš€ Bible AI ìƒ˜í”Œ ë°ì´í„° ì—…ë¡œë“œ")
    print("=" * 60)
    print(f"ğŸ“ íŒŒì¼: {DATA_FILE}")
    print(f"ğŸ¤– ëª¨ë¸: {MODEL_NAME}")
    print(f"ğŸ“ ì°¨ì›: {EMBEDDING_DIMENSION}ì°¨ì›")
    print(f"ğŸ’° OpenAI ìœ ë£Œ ëª¨ë¸ ì‚¬ìš© - ë” ì •í™•í•œ ì˜ë¯¸ ê²€ìƒ‰!")
    print(f"â± ì˜ˆìƒ ì‹œê°„: ì•½ 3-5ë¶„")
    print("=" * 60)
    
    print("\nì—…ë¡œë“œë¥¼ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
    print("ê³„ì†í•˜ë ¤ë©´ Enter, ì·¨ì†Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”...")
    
    try:
        input()
        print("\nğŸš€ ì—…ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # ì—…ë¡œë“œ ì‹¤í–‰
        upload_bible_data(batch_size=DEFAULT_BATCH_SIZE, max_items=None)
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì—…ë¡œë“œê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        print("ğŸ’¡ ë¡œê·¸ë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()
