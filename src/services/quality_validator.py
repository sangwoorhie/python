#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
í’ˆì§ˆ ê²€ì¦ ì„œë¹„ìŠ¤ ëª¨ë“ˆ
"""

import re
import logging
from typing import Dict, List
from src.utils.memory_manager import memory_cleanup
from src.utils.text_preprocessor import TextPreprocessor


class QualityValidator:
    """ë‹µë³€ í’ˆì§ˆ ê²€ì¦ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, openai_client):
        self.openai_client = openai_client
        self.text_processor = TextPreprocessor()
    
    def is_valid_text(self, text: str, lang: str = 'ko') -> bool:
        """í…ìŠ¤íŠ¸ ìœ íš¨ì„± ê²€ì¦ ë©”ì„œë“œ"""
        if not text or len(text.strip()) < 3:
            return False
        
        if lang == 'ko':
            return self.is_valid_korean_text(text)
        else:  # ì˜ì–´
            return self.is_valid_english_text(text)

    def is_valid_korean_text(self, text: str) -> bool:
        """í•œêµ­ì–´ í…ìŠ¤íŠ¸ì˜ ìœ íš¨ì„±ì„ ê²€ì¦í•˜ëŠ” ë©”ì„œë“œ"""
        if not text or len(text.strip()) < 3:
            logging.info(f"í•œêµ­ì–´ ê²€ì¦ ì‹¤íŒ¨: í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŒ (ê¸¸ì´: {len(text.strip()) if text else 0})")
            return False
        
        korean_chars = len(re.findall(r'[ê°€-í£]', text))
        total_chars = len(re.sub(r'\s', '', text))
        
        if total_chars == 0:
            logging.info("í•œêµ­ì–´ ê²€ì¦ ì‹¤íŒ¨: ì´ ê¸€ì ìˆ˜ê°€ 0")
            return False
            
        korean_ratio = korean_chars / total_chars
        logging.info(f"í•œêµ­ì–´ ë¹„ìœ¨: {korean_ratio:.3f} (í•œêµ­ì–´: {korean_chars}, ì „ì²´: {total_chars})")
        
        # í•œêµ­ì–´ ë¹„ìœ¨ ê¸°ì¤€ì„ ì™„í™” (0.2 â†’ 0.1)
        if korean_ratio < 0.1:
            logging.info(f"í•œêµ­ì–´ ê²€ì¦ ì‹¤íŒ¨: í•œêµ­ì–´ ë¹„ìœ¨ ë¶€ì¡± ({korean_ratio:.3f} < 0.1)")
            return False
        
        # ë¬´ì˜ë¯¸í•œ íŒ¨í„´ ê°ì§€ (GPT í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€)
        meaningless_patterns = [
            r'^[a-z\s\.,;:\(\)\[\]\-_&\/\'"]+$', # ì˜ì–´
            r'^[A-Z\s\.,;:\(\)\[\]\-_&\/\'"]+$', # ì˜ì–´ ëŒ€ë¬¸ì
            r'^[\s\.,;:\(\)\[\]\-_&\/\'"]+$',    # ê³µë°±
            r'^[0-9\s\.,;:\(\)\[\]\-_&\/\'"]+$', # ìˆ«ì
            r'.*[Ğ°-Ñ].*',                        # ëŸ¬ì‹œì•„ì–´
            r'.*[Î±-Ï‰].*',                        # ê·¸ë¦¬ìŠ¤ì–´
        ]
        
        for pattern in meaningless_patterns:
            if re.match(pattern, text, re.IGNORECASE):
                logging.info(f"í•œêµ­ì–´ ê²€ì¦ ì‹¤íŒ¨: ë¬´ì˜ë¯¸í•œ íŒ¨í„´ ê°ì§€")
                return False
        
        # ë°˜ë³µ ë¬¸ì ê°ì§€: ê°™ì€ ë¬¸ìê°€ 5ë²ˆ ì´ìƒ ì—°ì†ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ë©´ ë¹„ì •ìƒ í…ìŠ¤íŠ¸ë¡œ ê°„ì£¼
        if re.search(r'(.)\1{5,}', text):
            logging.info("í•œêµ­ì–´ ê²€ì¦ ì‹¤íŒ¨: ë°˜ë³µ ë¬¸ì ê°ì§€")
            return False
        
        # ì˜ì–´ ë¹„ìœ¨ ê²€ì‚¬ë¥¼ ì™„í™” (0.5 â†’ 0.7)
        random_pattern = r'[a-zA-Z]{8,}'
        if re.search(random_pattern, text) and korean_ratio < 0.3:
            logging.info(f"í•œêµ­ì–´ ê²€ì¦ ì‹¤íŒ¨: ê¸´ ì˜ì–´ ë‹¨ì–´ì™€ ë‚®ì€ í•œêµ­ì–´ ë¹„ìœ¨")
            return False
        
        logging.info("í•œêµ­ì–´ ê²€ì¦ ì„±ê³µ")
        return True

    def is_valid_english_text(self, text: str) -> bool:
        """ì˜ì–´ í…ìŠ¤íŠ¸ì˜ ìœ íš¨ì„±ì„ ê²€ì¦í•˜ëŠ” ë©”ì„œë“œ"""
        if not text or len(text.strip()) < 3:
            return False
        
        english_chars = len(re.findall(r'[a-zA-Z]', text))
        total_chars = len(re.sub(r'\s', '', text))
        
        if total_chars == 0:
            return False
            
        english_ratio = english_chars / total_chars
        
        if english_ratio < 0.7:  # ì˜ì–´ ë¹„ìœ¨ì´ 70% ë¯¸ë§Œì´ë©´ ë¬´íš¨
            return False
        
        # ë°˜ë³µ ë¬¸ì ê°ì§€
        if re.search(r'(.)\1{5,}', text):
            return False
        
        return True

    def check_answer_completeness(self, answer: str, query: str, lang: str = 'ko') -> float:
        """ìƒì„±ëœ ë‹µë³€ì˜ ì™„ì„±ë„ì™€ ìœ ìš©ì„±ì„ í‰ê°€"""
        
        try:
            # 1. ê¸°ë³¸ ê¸¸ì´ ê²€ì‚¬
            if len(answer.strip()) < 10:
                return 0.0
                
            # 2. ì‹¤ì§ˆì  ë‚´ìš© ë¹„ìœ¨ ê²€ì‚¬
            meaningful_content_ratio = self.calculate_meaningful_content_ratio(answer, lang)
            
            # 3. ì§ˆë¬¸-ë‹µë³€ ê´€ë ¨ì„± í‚¤ì›Œë“œ ë§¤ì¹­
            query_keywords = set(self.text_processor.extract_keywords(query.lower()))
            answer_keywords = set(self.text_processor.extract_keywords(answer.lower()))
            keyword_overlap = len(query_keywords & answer_keywords)
            keyword_relevance = keyword_overlap / max(len(query_keywords), 1) if query_keywords else 0.5
            
            # 4. ë‹µë³€ ì™„ê²°ì„± ê²€ì‚¬ (ë¬¸ì¥ì´ ì™„ì„±ë˜ì–´ ìˆëŠ”ì§€)
            completeness_score = self.check_sentence_completeness(answer, lang)
            
            # 5. êµ¬ì²´ì„± ê²€ì‚¬ (êµ¬ì²´ì ì¸ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€)
            specificity_score = self.check_answer_specificity(answer, query, lang)
            
            # 6. ì¢…í•© ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ í‰ê· )
            final_score = (
                meaningful_content_ratio * 0.3 +    # ì˜ë¯¸ìˆëŠ” ë‚´ìš© ë¹„ìœ¨
                keyword_relevance * 0.25 +          # í‚¤ì›Œë“œ ê´€ë ¨ì„±
                completeness_score * 0.25 +         # ë¬¸ì¥ ì™„ê²°ì„±
                specificity_score * 0.2             # êµ¬ì²´ì„±
            )
            
            logging.info(f"ë‹µë³€ ì™„ì„±ë„ ë¶„ì„: ë‚´ìš©ë¹„ìœ¨={meaningful_content_ratio:.2f}, "
                        f"í‚¤ì›Œë“œê´€ë ¨ì„±={keyword_relevance:.2f}, ì™„ê²°ì„±={completeness_score:.2f}, "
                        f"êµ¬ì²´ì„±={specificity_score:.2f}, ìµœì¢…ì ìˆ˜={final_score:.2f}")
            
            return min(final_score, 1.0)
            
        except Exception as e:
            logging.error(f"ë‹µë³€ ì™„ì„±ë„ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return 0.5  # ì˜¤ë¥˜ì‹œ ì¤‘ê°„ê°’ ë°˜í™˜

    def calculate_meaningful_content_ratio(self, text: str, lang: str = 'ko') -> float:
        """í…ìŠ¤íŠ¸ì—ì„œ ì˜ë¯¸ìˆëŠ” ë‚´ìš©ì˜ ë¹„ìœ¨ì„ ê³„ì‚°"""
        
        if not text:
            return 0.0
            
        # HTML íƒœê·¸ ì œê±°
        clean_text = re.sub(r'<[^>]+>', '', text)
        
        if lang == 'ko':
            # í•œêµ­ì–´ ë¶ˆìš©êµ¬ ì œê±°
            filler_patterns = [
                r'ì•ˆë…•í•˜ì„¸ìš”[^.]*\.',
                r'ê°ì‚¬[ë“œë¦½]*ë‹ˆë‹¤[^.]*\.',
                r'í‰ì•ˆí•˜ì„¸ìš”[^.]*\.',
                r'ì£¼ë‹˜\s*ì•ˆì—ì„œ[^.]*\.',
                r'ë°”ì´ë¸”\s*ì• í”Œ[^.]*\.',
                r'GOODTV[^.]*\.',
                r'ë¬¸ì˜[í•´ì£¼ì…”ì„œ]*\s*ê°ì‚¬[^.]*\.',
                r'ì•ˆë‚´[í•´]*ë“œë¦¬ê² ìŠµë‹ˆë‹¤[^.]*\.',
                r'ë„ì›€ì´\s*[ë˜]*[ì‹œ]*[ê¸¸]*[ë°”ë¼]*[ë©°]*[^.]*\.',
                r'í•­ìƒ[^.]*ë°”ì´ë¸”\s*ì• í”Œ[^.]*\.'
            ]
        else:
            # ì˜ì–´ ë¶ˆìš©êµ¬ ì œê±°
            filler_patterns = [
                r'Hello[^.]*\.',
                r'Thank you[^.]*\.',
                r'Best regards[^.]*\.',
                r'God bless[^.]*\.',
                r'Bible App[^.]*\.',
                r'GOODTV[^.]*\.',
                r'We will[^.]*\.',
                r'Please contact[^.]*\.'
            ]
        
        # ë¶ˆìš©êµ¬ ì œê±°
        for pattern in filler_patterns:
            clean_text = re.sub(pattern, '', clean_text, flags=re.IGNORECASE)
        
        # ê³µë°± ì •ë¦¬
        clean_text = re.sub(r'\s+', ' ', clean_text).strip()
        
        # ì˜ë¯¸ìˆëŠ” ë‚´ìš© ë¹„ìœ¨ ê³„ì‚°
        original_length = len(re.sub(r'<[^>]+>', '', text).strip())
        meaningful_length = len(clean_text)
        
        if original_length == 0:
            return 0.0
            
        ratio = meaningful_length / original_length
        return min(ratio, 1.0)

    def check_sentence_completeness(self, text: str, lang: str = 'ko') -> float:
        """ë¬¸ì¥ì´ ì™„ì„±ë˜ì–´ ìˆëŠ”ì§€ ê²€ì‚¬"""
        
        if not text:
            return 0.0
            
        # HTML íƒœê·¸ ì œê±°
        clean_text = re.sub(r'<[^>]+>', '', text).strip()
        
        if len(clean_text) < 5:
            return 0.0
        
        # ë¬¸ì¥ ë í‘œì‹œ í™•ì¸
        if lang == 'ko':
            sentence_endings = r'[.!?ë‹ˆë‹¤ìš”ìŒë©ë‹¤ìŒê¹Œë‹¤í•˜ì„¸ìš”ìŠµë‹ˆë‹¤ë‹ˆê¹Œ]'
        else:
            sentence_endings = r'[.!?]'
        
        # ë§ˆì§€ë§‰ ë¬¸ì¥ì´ ì™„ì„±ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if re.search(sentence_endings + r'\s*$', clean_text):
            return 1.0
        
        # ì¤‘ê°„ì— ì™„ì„±ëœ ë¬¸ì¥ì´ ìˆëŠ”ì§€ í™•ì¸
        sentences = re.split(sentence_endings, clean_text)
        if len(sentences) > 1:
            return 0.7  # ë¶€ë¶„ì ìœ¼ë¡œ ì™„ì„±ë¨
        
        # ë¬¸ì¥ì´ ë¶ˆì™„ì „í•œ ê²½ìš°
        return 0.3

    def check_answer_specificity(self, answer: str, query: str, lang: str = 'ko') -> float:
        """ë‹µë³€ì´ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ”ì§€ ê²€ì‚¬ (ë¹ˆ ì•½ì† íŒ¨í„´ ì—„ê²© ê°ì§€)"""
        
        if not answer:
            return 0.0
        
        # ë¹ˆ ì•½ì† íŒ¨í„´ ì—„ê²© ê°ì§€
        empty_promise_score = self.detect_empty_promises(answer, lang)
        if empty_promise_score < 0.3:  # ë¹ˆ ì•½ì†ì´ ê°ì§€ë˜ë©´ ë§¤ìš° ë‚®ì€ ì ìˆ˜
            logging.warning(f"ë¹ˆ ì•½ì† íŒ¨í„´ ê°ì§€! ì ìˆ˜: {empty_promise_score:.2f}")
            return empty_promise_score
            
        specificity_score = 0.0
        
        if lang == 'ko':
            # êµ¬ì²´ì  ì •ë³´ íŒ¨í„´ (í•œêµ­ì–´) - ë” ì—„ê²©í•˜ê²Œ ê°•í™”
            specific_patterns = [
                r'\d+[ê°€ì§€ê°œë‹¨ê³„ë²ˆì§¸ì°¨ë¡€]',  # ìˆ«ìê°€ í¬í•¨ëœ ë‹¨ê³„
                r'[ë©”ë‰´ì„¤ì •í™”ë©´ë²„íŠ¼íƒ­]ì—ì„œ',    # êµ¬ì²´ì  ìœ„ì¹˜
                r'ë‹¤ìŒê³¼\s*ê°™[ì€ì´]',         # êµ¬ì²´ì  ë°©ë²• ì œì‹œ
                r'[í´ë¦­ì„ íƒí„°ì¹˜ëˆ„ë¥´]',         # êµ¬ì²´ì  ë™ì‘
                r'[ë°©ë²•ë‹¨ê³„ì ˆì°¨ê³¼ì •]',         # êµ¬ì²´ì  í”„ë¡œì„¸ìŠ¤
                r'\w+\s*ë²„íŠ¼',               # ë²„íŠ¼ëª…
                r'\w+\s*ë©”ë‰´',               # ë©”ë‰´ëª…
                r'NIV|KJV|ESV|ë²ˆì—­ë³¸',       # êµ¬ì²´ì  ë²ˆì—­ë³¸
                r'[ìƒí•˜ì¢Œìš°]ë‹¨[ì—ì˜]',         # êµ¬ì²´ì  ìœ„ì¹˜
                r'ì„¤ì •[ì—ì„œìœ¼ë¡œ]',            # ì„¤ì • ê´€ë ¨
                r'í™”ë©´\s*[ìƒí•˜ì¢Œìš°ì¤‘ì•™]',      # í™”ë©´ ìœ„ì¹˜
                r'íƒ­í•˜ì—¬|í´ë¦­í•˜ì—¬|í„°ì¹˜í•˜ì—¬',    # êµ¬ì²´ì  í–‰ë™
                r'ë‹¤ìŒ\s*ìˆœì„œ',              # ìˆœì„œ ì•ˆë‚´
                r'ë¨¼ì €|ê·¸ë‹¤ìŒ|ë§ˆì§€ë§‰ìœ¼ë¡œ'       # ë‹¨ê³„ë³„ ì•ˆë‚´
            ]
            
            # ë¹ˆ ì•½ì†/ëª¨í˜¸í•œ í‘œí˜„ íŒ¨í„´ (ë” ì—„ê²©í•˜ê²Œ)
            vague_patterns = [
                r'ì•ˆë‚´[í•´]*ë“œë¦¬ê² ìŠµë‹ˆë‹¤',
                r'ë„ì›€[ì„ì´]\s*ë“œë¦¬ê² ìŠµë‹ˆë‹¤',
                r'í™•ì¸[í•˜ê³ í•˜ì—¬í•´ì„œ]',
                r'ê²€í† [í•˜ê³ í•˜ì—¬]',
                r'ì¤€ë¹„[í•˜ê³ í•˜ê² ìŠµë‹ˆë‹¤]',
                r'ì „ë‹¬[í•˜ê³ í•˜ê² ë“œë¦¬ê² ]',
                r'ì œê³µ[í•˜ê³ í•˜ê² ë“œë¦¬ê² ]',
                r'ë…¸ë ¥[í•˜ê³ í•˜ê² ]',
                r'ì‚´í´[ë³´ê³ ë³´ê² ]',
                r'ë°©ë²•[ì„ì´]\s*ì°¾ì•„[ë“œë¦¬ê² ë³´ê² ]'
            ]
        else:
            # êµ¬ì²´ì  ì •ë³´ íŒ¨í„´ (ì˜ì–´)
            specific_patterns = [
                r'\d+\s*steps?',
                r'follow\s+these',
                r'click\s+on',
                r'go\s+to',
                r'select\s+\w+',
                r'settings?\s+menu',
                r'NIV|KJV|ESV|translation',
                r'top\s+of\s+screen',
                r'button\s+\w+'
            ]
            
            vague_patterns = [
                r'we\s+will\s+review',
                r'we\s+are\s+working',
                r'please\s+contact',
                r'will\s+be\s+available'
            ]
        
        # êµ¬ì²´ì„± ì ìˆ˜ ê³„ì‚°
        specific_count = 0
        for pattern in specific_patterns:
            specific_count += len(re.findall(pattern, answer, re.IGNORECASE))
        
        vague_count = 0
        for pattern in vague_patterns:
            vague_count += len(re.findall(pattern, answer, re.IGNORECASE))
        
        # êµ¬ì²´ì  ì •ë³´ê°€ ë§ê³  ëª¨í˜¸í•œ í‘œí˜„ì´ ì ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
        if specific_count > 0:
            specificity_score = specific_count / (specific_count + vague_count + 1)
        else:
            specificity_score = 0.1 if vague_count == 0 else 0.0
        
        return min(specificity_score, 1.0)

    def detect_empty_promises(self, answer: str, lang: str = 'ko') -> float:
        """ì•½ì†ë§Œ í•˜ê³  ì‹¤ì œ ë‚´ìš©ì´ ì—†ëŠ” ë¹ˆ ì•½ì† íŒ¨í„´ì„ ê°ì§€"""
        
        if not answer:
            return 0.0
        
        # HTML íƒœê·¸ ì œê±°í•˜ì—¬ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ë¶„ì„
        clean_text = re.sub(r'<[^>]+>', '', answer)
        
        if lang == 'ko':
            # ìœ„í—˜í•œ ì•½ì† í‘œí˜„ë“¤ (ì´í›„ ì‹¤ì œ ë‚´ìš©ì´ ì™€ì•¼ í•¨)
            promise_patterns = [
                r'ì•ˆë‚´[í•´]*ë“œë¦¬ê² ìŠµë‹ˆë‹¤',
                r'ë„ì›€[ì„ì´]?\s*ë“œë¦¬ê² ìŠµë‹ˆë‹¤',
                r'ë°©ë²•[ì„ì´]?\s*ì•ˆë‚´[í•´]*ë“œë¦¬ê² ìŠµë‹ˆë‹¤',
                r'ì„¤ëª…[í•´]*ë“œë¦¬ê² ìŠµë‹ˆë‹¤',
                r'ì•Œë ¤[ë“œë¦¬ê² ë“œë¦´]',
                r'ì œê³µ[í•´]*ë“œë¦¬ê² ìŠµë‹ˆë‹¤',
                r'ë„ì™€[ë“œë¦¬ê² ë“œë¦´]',
                r'ì°¾ì•„[ë“œë¦¬ê² ë“œë¦´]'
            ]
            
            # ì‹¤ì œ ë‚´ìš©ì„ ë‚˜íƒ€ë‚´ëŠ” íŒ¨í„´ë“¤
            content_patterns = [
                r'\d+\.\s*',                    # ë²ˆí˜¸ ë§¤ê¸°ê¸° (1., 2., ...)
                r'ë¨¼ì €',                       # ë‹¨ê³„ë³„ ì„¤ëª… ì‹œì‘
                r'ë‹¤ìŒê³¼?\s*ê°™[ì€ì´]',           # êµ¬ì²´ì  ë°©ë²• ì œì‹œ
                r'[ë©”ë‰´ì„¤ì •í™”ë©´ë²„íŠ¼]',           # êµ¬ì²´ì  UI ìš”ì†Œ
                r'í´ë¦­|í„°ì¹˜|ì„ íƒ|ì´ë™',          # êµ¬ì²´ì  í–‰ë™
                r'NIV|KJV|ESV',               # êµ¬ì²´ì  ë²ˆì—­ë³¸
                r'ìƒë‹¨|í•˜ë‹¨|ì¢Œì¸¡|ìš°ì¸¡',         # êµ¬ì²´ì  ìœ„ì¹˜
                r'ì„¤ì •ì—ì„œ|ë©”ë‰´ì—ì„œ',           # êµ¬ì²´ì  ê²½ë¡œ
                r'ë‹¤ìŒ\s*[ìˆœì„œë‹¨ê³„ë°©ë²•ì ˆì°¨]',    # ë‹¨ê³„ë³„ ì•ˆë‚´
                r'[0-9]+[ë²ˆì§¸ë‹¨ê³„]',           # ìˆœì„œ í‘œì‹œ
                r'í™”ë©´\s*[ìƒí•˜ì¢Œìš°ì¤‘ì•™]'        # ìœ„ì¹˜ ì„¤ëª…
            ]
        else:  # ì˜ì–´
            promise_patterns = [
                r'will\s+guide\s+you',
                r'will\s+help\s+you',
                r'will\s+show\s+you',
                r'will\s+provide',
                r'let\s+me\s+help',
                r'here[\'\"]s\s+how'
            ]
            
            content_patterns = [
                r'\d+\.\s*',
                r'first|second|third',
                r'step\s+\d+',
                r'click|tap|select',
                r'menu|setting|screen',
                r'NIV|KJV|ESV',
                r'top|bottom|left|right'
            ]
        
        # ì•½ì† í‘œí˜„ ì°¾ê¸°
        promise_count = 0
        promise_positions = []
        
        for pattern in promise_patterns:
            matches = list(re.finditer(pattern, clean_text, re.IGNORECASE))
            promise_count += len(matches)
            promise_positions.extend([match.start() for match in matches])
        
        if promise_count == 0:
            return 0.8  # ì•½ì† í‘œí˜„ì´ ì—†ìœ¼ë©´ ì¤‘ê°„ ì ìˆ˜
        
        # ì•½ì† ì´í›„ì— ì‹¤ì œ ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸
        content_after_promise = 0
        total_text_after_promises = 0
        
        for pos in promise_positions:
            # ì•½ì† í‘œí˜„ ì´í›„ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text_after = clean_text[pos:]
            
            # ëë§ºìŒë§ ì œê±°í•˜ì—¬ ì‹¤ì œ ë‚´ìš©ë§Œ ê²€ì‚¬
            text_after = re.sub(r'í•­ìƒ\s*ì„±ë„ë‹˜ê»˜[^.]*\.', '', text_after, flags=re.IGNORECASE)
            text_after = re.sub(r'ê°ì‚¬í•©ë‹ˆë‹¤[^.]*\.', '', text_after, flags=re.IGNORECASE)
            text_after = re.sub(r'ì£¼ë‹˜\s*ì•ˆì—ì„œ[^.]*\.', '', text_after, flags=re.IGNORECASE)
            text_after = re.sub(r'í‰ì•ˆí•˜ì„¸ìš”[^.]*\.', '', text_after, flags=re.IGNORECASE)
            
            total_text_after_promises += len(text_after.strip())
            
            # ì‹¤ì œ ë‚´ìš© íŒ¨í„´ì´ ìˆëŠ”ì§€ í™•ì¸
            for content_pattern in content_patterns:
                if re.search(content_pattern, text_after, re.IGNORECASE):
                    content_after_promise += 1
                    break
        
        # ì ìˆ˜ ê³„ì‚°
        if promise_count > 0:
            # ì•½ì† ëŒ€ë¹„ ì‹¤ì œ ë‚´ìš© ë¹„ìœ¨
            content_ratio = content_after_promise / promise_count
            
            # ì•½ì† ì´í›„ í…ìŠ¤íŠ¸ ê¸¸ì´ ë¹„ìœ¨ (í‰ê· )
            avg_length_after = total_text_after_promises / len(promise_positions) if promise_positions else 0
            length_score = min(avg_length_after / 100, 1.0)  # 100ì ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”
            
            # ìµœì¢… ì ìˆ˜ (ë‚´ìš© ë¹„ìœ¨ê³¼ ê¸¸ì´ë¥¼ ê³ ë ¤)
            final_score = content_ratio * 0.7 + length_score * 0.3
            
            logging.info(f"ë¹ˆ ì•½ì† ë¶„ì„: ì•½ì†={promise_count}ê°œ, ì‹¤ì œë‚´ìš©={content_after_promise}ê°œ, "
                        f"ë‚´ìš©ë¹„ìœ¨={content_ratio:.2f}, ê¸¸ì´ì ìˆ˜={length_score:.2f}, ìµœì¢…ì ìˆ˜={final_score:.2f}")
            
            return final_score
        
        return 0.5  # ê¸°ë³¸ê°’

    def detect_hallucination_and_inconsistency(self, answer: str, query: str, lang: str = 'ko') -> dict:
        """ìƒì„±ëœ ë‹µë³€ì—ì„œ í• ë£¨ì‹œë„¤ì´ì…˜ê³¼ ì¼ê´€ì„± ë¬¸ì œë¥¼ ê°ì§€"""
        
        issues = {
            'external_app_recommendation': False,
            'bible_app_domain_violation': False,
            'content_inconsistency': False,
            'translation_switching': False,
            'invalid_features': False,
            'overall_score': 1.0,
            'detected_issues': []
        }
        
        if not answer:
            return issues
        
        # HTML íƒœê·¸ ì œê±°í•˜ì—¬ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ë¶„ì„
        clean_answer = re.sub(r'<[^>]+>', '', answer)
        clean_query = re.sub(r'<[^>]+>', '', query)
        
        if lang == 'ko':
            # 1. ì™¸ë¶€ ì•± ì¶”ì²œ ê°ì§€ (ì¹˜ëª…ì )
            external_app_patterns = [
                r'Parallel\s*Bible',
                r'ë³‘ë ¬\s*ì„±ê²½\s*ì•±',
                r'ë‹¤ë¥¸\s*ì•±ì„?\s*(ë‹¤ìš´ë¡œë“œ|ì„¤ì¹˜)',
                r'ì•±\s*ìŠ¤í† ì–´ì—ì„œ\s*(ê²€ìƒ‰|ë‹¤ìš´ë¡œë“œ)',
                r'êµ¬ê¸€\s*í”Œë ˆì´\s*ìŠ¤í† ì–´',
                r'ì™¸ë¶€\s*(ì•±|ì–´í”Œë¦¬ì¼€ì´ì…˜)',
                r'ë³„ë„[ì˜]*\s*(ì•±|ì–´í”Œ)',
                r'ì¶”ê°€ë¡œ\s*(ì•±ì„|ì–´í”Œì„)\s*ì„¤ì¹˜'
            ]
            
            for pattern in external_app_patterns:
                if re.search(pattern, clean_answer, re.IGNORECASE):
                    issues['external_app_recommendation'] = True
                    issues['detected_issues'].append(f"ì™¸ë¶€ ì•± ì¶”ì²œ ê°ì§€: {pattern}")
                    issues['overall_score'] -= 0.8  # ë§¤ìš° ì‹¬ê°í•œ ê°ì 
            
            # 2. ë²ˆì—­ë³¸ ë³€ê²½/êµì²´ ê°ì§€ (ì§ˆë¬¸ vs ë‹µë³€)
            query_translations = self.text_processor.extract_translations_from_text(clean_query)
            answer_translations = self.text_processor.extract_translations_from_text(clean_answer)
            
            if query_translations and answer_translations:
                # ì§ˆë¬¸ì—ì„œ ì–¸ê¸‰í•œ ë²ˆì—­ë³¸ì´ ë‹µë³€ì—ì„œ ë‹¤ë¥¸ ë²ˆì—­ë³¸ìœ¼ë¡œ ë°”ë€Œì—ˆëŠ”ì§€ í™•ì¸
                query_set = set(query_translations)
                answer_set = set(answer_translations)
                
                # ì§ˆë¬¸ì— ì—†ë˜ ë²ˆì—­ë³¸ì´ ë‹µë³€ì— ì¶”ê°€ë˜ì—ˆëŠ”ì§€ í™•ì¸
                unexpected_translations = answer_set - query_set
                if unexpected_translations:
                    # ì™„ì „íˆ ë‹¤ë¥¸ ë²ˆì—­ë³¸(ì˜ˆ: ê°œì—­í•œê¸€ â†’ ì˜ë¬¸ì„±ê²½)ì€ ê¸ˆì§€
                    problematic = False
                    for trans in unexpected_translations:
                        if any(forbidden in trans.lower() for forbidden in ['ì˜ì–´', 'english', 'niv', 'kjv', 'esv']) and \
                           not any(allowed in q_trans.lower() for q_trans in query_translations for allowed in ['ì˜ì–´', 'english', 'niv', 'kjv', 'esv']):
                            problematic = True
                            break
                        elif any(forbidden in trans.lower() for forbidden in ['í•œê¸€', 'ê°œì—­', 'korean']) and \
                             not any(allowed in q_trans.lower() for q_trans in query_translations for allowed in ['í•œê¸€', 'ê°œì—­', 'korean']):
                            problematic = True
                            break
                    
                    if problematic:
                        issues['translation_switching'] = True
                        issues['detected_issues'].append(f"ë²ˆì—­ë³¸ ë³€ê²½: {query_translations} â†’ {list(unexpected_translations)}")
                        issues['overall_score'] -= 0.7
        
        # ìµœì¢… ì ìˆ˜ ì •ê·œí™”
        issues['overall_score'] = max(issues['overall_score'], 0.0)
        
        # ì‹¬ê°í•œ ë¬¸ì œê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ì „ì²´ ì ìˆ˜ë¥¼ ë§¤ìš° ë‚®ê²Œ
        critical_issues = [
            issues['external_app_recommendation'],
            issues['translation_switching'],
        ]
        
        if any(critical_issues):
            issues['overall_score'] = min(issues['overall_score'], 0.2)
        
        logging.info(f"í• ë£¨ì‹œë„¤ì´ì…˜ ê²€ì¦ ê²°ê³¼: ì ìˆ˜={issues['overall_score']:.2f}, ë¬¸ì œ={len(issues['detected_issues'])}ê°œ")
        
        return issues

    def validate_answer_relevance_ai(self, answer: str, query: str, question_analysis: dict) -> bool:
        """AIë¥¼ ì´ìš©í•´ ìƒì„±ëœ ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€ ì—„ê²©í•˜ê²Œ ê²€ì¦"""
        
        try:
            with memory_cleanup():
                system_prompt = """ë‹¹ì‹ ì€ ë‹µë³€ í’ˆì§ˆ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ìƒì„±ëœ ë‹µë³€ì´ ê³ ê°ì˜ ì§ˆë¬¸ì— ì ì ˆíˆ ëŒ€ì‘í•˜ëŠ”ì§€ ì—„ê²©í•˜ê²Œ í‰ê°€í•˜ì„¸ìš”.

âš ï¸ ì—„ê²©í•œ í‰ê°€ ê¸°ì¤€:
1. ë‹µë³€ì´ ì§ˆë¬¸ì˜ í•µì‹¬ í–‰ë™ ìš”ì²­ê³¼ ì¼ì¹˜í•˜ëŠ”ê°€? (ë³µì‚¬â‰ ì¬ìƒ)
2. ë‹µë³€ì´ ì§ˆë¬¸ì˜ ì£¼ì œ ì˜ì—­ê³¼ ì¼ì¹˜í•˜ëŠ”ê°€? (í…ìŠ¤íŠ¸â‰ ìŒì„±)
3. ë‹µë³€ì´ ì‹¤ì œ ë¬¸ì œ í•´ê²°ì— ì§ì ‘ì ìœ¼ë¡œ ë„ì›€ì´ ë˜ëŠ”ê°€?
4. ë‹µë³€ì—ì„œ ì–¸ê¸‰í•˜ëŠ” ê¸°ëŠ¥ì´ ì§ˆë¬¸ì—ì„œ ìš”ì²­í•œ ê¸°ëŠ¥ê³¼ ê°™ì€ê°€?

ğŸš« ë¶€ì ì ˆí•œ ë‹µë³€ ì˜ˆì‹œ:
- í…ìŠ¤íŠ¸ ë³µì‚¬ ì§ˆë¬¸ì— ìŒì„± ì¬ìƒ ë‹µë³€
- ê²€ìƒ‰ ê¸°ëŠ¥ ì§ˆë¬¸ì— ì„¤ì • ë³€ê²½ ë‹µë³€  
- ì˜¤ë¥˜ ì‹ ê³ ì— ì¼ë°˜ ì‚¬ìš©ë²• ë‹µë³€
- êµ¬ì²´ì  ê¸°ëŠ¥ ì§ˆë¬¸ì— ì¶”ìƒì  ì•ˆë‚´ ë‹µë³€

ê²°ê³¼: "relevant" ë˜ëŠ” "irrelevant" ì¤‘ í•˜ë‚˜ë§Œ ë°˜í™˜í•˜ì„¸ìš”."""

                user_prompt = f"""ì§ˆë¬¸ ë¶„ì„:
ì˜ë„: {question_analysis.get('intent_type', 'N/A')}
ì£¼ì œ: {question_analysis.get('main_topic', 'N/A')}
í–‰ë™ìœ í˜•: {question_analysis.get('action_type', 'N/A')}
ìš”ì²­ì‚¬í•­: {question_analysis.get('specific_request', 'N/A')}

ì›ë³¸ ì§ˆë¬¸: {query}

ìƒì„±ëœ ë‹µë³€: {answer}

âš ï¸ íŠ¹íˆ ì£¼ì˜: ì§ˆë¬¸ì˜ í–‰ë™ìœ í˜•ê³¼ ë‹µë³€ì—ì„œ ë‹¤ë£¨ëŠ” í–‰ë™ì´ ë‹¤ë¥´ë©´ "irrelevant"ì…ë‹ˆë‹¤.
ì´ ë‹µë³€ì´ ì§ˆë¬¸ì— ì ì ˆí•œì§€ ì—„ê²©í•˜ê²Œ í‰ê°€í•´ì£¼ì„¸ìš”."""

                response = self.openai_client.chat.completions.create(
                    model='gpt-3.5-turbo',
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    max_tokens=30,
                    temperature=0.1
                )
                
                result = response.choices[0].message.content.strip().lower()
                
                is_relevant = 'relevant' in result and 'irrelevant' not in result
                
                logging.info(f"AI ë‹µë³€ ê´€ë ¨ì„± ê²€ì¦: {result} -> {is_relevant}")
                
                return is_relevant
                
        except Exception as e:
            logging.error(f"AI ë‹µë³€ ê´€ë ¨ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ì ì¸ í‚¤ì›Œë“œ ë§¤ì¹­
            query_keywords = set(self.text_processor.extract_keywords(query.lower()))
            answer_keywords = set(self.text_processor.extract_keywords(answer.lower()))
            
            keyword_overlap = len(query_keywords & answer_keywords)
            keyword_relevance = keyword_overlap / max(len(query_keywords), 1)
            
            return keyword_relevance >= 0.2  # 20% ì´ìƒ í‚¤ì›Œë“œ ì¼ì¹˜ì‹œ ê´€ë ¨ì„± ìˆìŒìœ¼ë¡œ íŒë‹¨
