#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
í†µí•© í…ìŠ¤íŠ¸ ë¶„ì„ê¸° ëª¨ë“ˆ
- ì˜¤íƒ€ ìˆ˜ì •ê³¼ ì˜ë„ ë¶„ì„ì„ í•œ ë²ˆì˜ GPT í˜¸ì¶œë¡œ ì²˜ë¦¬
- API ë¹„ìš© ì ˆê° ë° ì²˜ë¦¬ ì„±ëŠ¥ ìµœì í™”
"""

import logging
import json
from typing import Dict, Tuple
from src.utils.memory_manager import memory_cleanup

class UnifiedTextAnalyzer:
    """ì˜¤íƒ€ ìˆ˜ì • + ì˜ë„ ë¶„ì„ì„ í†µí•©í•œ ë¶„ì„ê¸°"""
    
    def __init__(self, openai_client):
        self.openai_client = openai_client
        self.model = 'gpt-5-mini'
    
    # í•œ ë²ˆì˜ GPT í˜¸ì¶œë¡œ ì˜¤íƒ€ ìˆ˜ì •ê³¼ ì˜ë„ ë¶„ì„ì„ ë™ì‹œì— ìˆ˜í–‰    
    # Args:
    #     text: ë¶„ì„í•  í…ìŠ¤íŠ¸
    # Returns:
    #     Tuple[str, Dict]: (ìˆ˜ì •ëœ_í…ìŠ¤íŠ¸, ì˜ë„_ë¶„ì„_ê²°ê³¼)
    def analyze_and_correct(self, text: str) -> Tuple[str, Dict]:
        try:
            with memory_cleanup():
                logging.info(f"====================== ì˜ë„ ë¶„ì„ + ì˜¤íƒ€ ìˆ˜ì • ì‹œì‘ ======================")
                
                # í†µí•© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
                system_prompt = """ë°”ì´ë¸” ì•± ë¬¸ì˜ ì „ë¬¸ ë¶„ì„ê°€ë¡œì„œ, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¤ìŒ ë‘ ê°€ì§€ ì‘ì—…ì„ ë™ì‹œì— ìˆ˜í–‰í•˜ì„¸ìš”:

    1. ì˜¤íƒ€ ìˆ˜ì •: ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ì˜¤íƒ€, ë„ì–´ì“°ê¸°, ë§ì¶¤ë²•ì„ êµì •í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê³  ì˜¬ë°”ë¥¸ í•œê¸€ í…ìŠ¤íŠ¸ë¡œ ìˆ˜ì •í•˜ì„¸ìš”. ì˜ë¯¸ì™€ ì–´ì¡°ëŠ” ìœ ì§€í•˜ì„¸ìš”.
    2. ì˜ë„ ë¶„ì„: ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ í•µì‹¬ ì˜ë„ì™€ ê´€ë ¨ ìš”ì†Œë¥¼ ë¶„ì„í•˜ì„¸ìš”.

    ì‘ë‹µ í˜•ì‹ (JSON):
    {
        "corrected_text": "ìˆ˜ì •ëœ í…ìŠ¤íŠ¸",
        "intent_analysis": {
            "core_intent": "í•µì‹¬ ì˜ë„",
            "intent_category": "ì¹´í…Œê³ ë¦¬",
            "primary_action": "ì£¼ìš” í–‰ë™",
            "semantic_keywords": ["ì˜ë¯¸ë¡ ì  í•µì‹¬ í‚¤ì›Œë“œë“¤"]
        }
    }

    ê·œì¹™:
    - ì•±/ì–´í”Œë¦¬ì¼€ì´ì…˜ â†’ ì•± í†µì¼
    - ë„ì–´ì“°ê¸°, ë§ì¶¤ë²• êµì •
    - ì˜ë¯¸/ì–´ì¡° ìœ ì§€
    - ìœ íš¨í•œ JSONë§Œ ë°˜í™˜
    - ë°”ì´ë¸” ì• í”Œ ì•± ê¸°ëŠ¥ê³¼ ê´€ë ¨ì—†ëŠ” í‚¤ì›Œë“œëŠ” ìˆ˜ì§‘í•˜ì§€ ë§ ê²ƒ"""

                user_prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n{text}"
                
                # GPT API í˜¸ì¶œ (gpt-5-mini ëª¨ë¸ì— ë§ëŠ” íŒŒë¼ë¯¸í„° ì‚¬ìš©)
                response = self.openai_client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    max_completion_tokens=120000,
                    response_format={"type": "json_object"}
                    # temperature íŒŒë¼ë¯¸í„° ì œê±° (gpt-5-miniì—ì„œ ì§€ì›í•˜ì§€ ì•ŠìŒ)
                )
                
                raw_content = response.choices[0].message.content
                if isinstance(raw_content, list):
                    # contentê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (ìƒˆ SDK í¬ë§·)
                    result_text = "".join([c.get("text", "") for c in raw_content if c.get("type") == "text"]).strip()
                else:
                    result_text = (raw_content or "").strip()
                
                # ğŸ” GPT ì‘ë‹µ ê²€ì¦ ë° ë¡œê¹… ê°•í™”
                logging.info(f"í†µí•© ë¶„ì„ - GPT ì›ë³¸ ì‘ë‹µ: {result_text}")
                logging.debug(f"GPT ì‘ë‹µ ì „ì²´ êµ¬ì¡°: {response.model_dump_json(indent=2)}")
                # ë¹ˆ ì‘ë‹µ ì²´í¬ ë° ìƒì„¸ ë¡œê¹…
                if not result_text or result_text.isspace():
                    logging.error("GPT ì‘ë‹µì´ ë¹„ì–´ìˆìŒ - ê¸°ë³¸ê°’ ë°˜í™˜")
                    logging.error(f"GPT ì‘ë‹µ ìƒì„¸: result_text='{result_text}', len={len(result_text) if result_text else 0}")
                    logging.error(f"GPT ì‘ë‹µ ê°ì²´: {response}")
                    logging.error(f"GPT ì‘ë‹µ choices: {response.choices if hasattr(response, 'choices') else 'N/A'}")
                    return text, self._get_default_intent_analysis(text)
                
                # JSON íŒŒì‹± ì‹œë„
                try:
                    result = json.loads(result_text)
                    corrected_text = result.get('corrected_text', text)
                    intent_analysis = result.get('intent_analysis', {})
                    
                    # ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í•„ë“œ ì¶”ê°€
                    intent_analysis.update({
                        'intent_type': intent_analysis.get('intent_category', 'ì¼ë°˜ë¬¸ì˜'),
                        'main_topic': intent_analysis.get('target_object', 'ê¸°íƒ€'),
                        'specific_request': intent_analysis.get('standardized_query', text[:100]),
                        'keywords': intent_analysis.get('semantic_keywords', [text[:20]]),
                        'urgency': 'medium',
                        'action_type': intent_analysis.get('primary_action', 'ê¸°íƒ€')
                    })
                    
                    # ìƒì„¸ ê²°ê³¼ ë¡œê·¸
                    logging.info(f"ğŸ” ì˜¤íƒ€ ìˆ˜ì •ëœ í…ìŠ¤íŠ¸: '{corrected_text}'")
                    logging.info(f"ğŸ” ì˜ë„ ë¶„ì„ ê²°ê³¼: {json.dumps(intent_analysis, ensure_ascii=False)}")
                    
                    # ë¡œê¹…
                    # if corrected_text != text:
                    #     logging.info(f"í†µí•© ë¶„ì„ - ì˜¤íƒ€ ìˆ˜ì •: '{text[:50]}...' â†’ '{corrected_text[:50]}...'")
                    
                    # logging.info(f"í†µí•© ë¶„ì„ - ì˜ë„: {intent_analysis.get('core_intent', 'N/A')}")
                    
                    # ğŸ” ë””ë²„ê·¸: íŒŒì‹±ëœ ê²°ê³¼ ì¶œë ¥
                    # logging.info("ï¿½ï¿½ [ì‚¬ìš©ì ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ê²°ê³¼]")
                    # logging.info(f"ì…ë ¥ í…ìŠ¤íŠ¸: {text}")
                    # logging.info(f"ìˆ˜ì •ëœ í…ìŠ¤íŠ¸: {corrected_text}")
                    # logging.info(f"í•µì‹¬ ì˜ë„: {intent_analysis.get('core_intent', 'N/A')}")
                    # logging.info(f"ì£¼ìš” í–‰ë™: {intent_analysis.get('primary_action', 'N/A')}")
                    # logging.info(f"ëŒ€ìƒ ê°ì²´: {intent_analysis.get('target_object', 'N/A')}")
                    # logging.info(f"ì˜ë¯¸ë¡ ì  í‚¤ì›Œë“œ: {intent_analysis.get('semantic_keywords', [])}")
                    # logging.info(f"ì „ì²´ ì˜ë„ ë¶„ì„: {json.dumps(intent_analysis, ensure_ascii=False, indent=2)}")
                    # logging.info("="*60)

                    return corrected_text, intent_analysis
                    
                except json.JSONDecodeError as e:
                    logging.error(f"í†µí•© ë¶„ì„ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                    logging.error(f"íŒŒì‹± ì‹¤íŒ¨í•œ ì‘ë‹µ: {result_text}")
                    
                    # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ í…ìŠ¤íŠ¸ ê¸°ë°˜ íŒŒì‹± ì‹œë„
                    corrected_text, intent_analysis = self._parse_text_response(result_text, text)
                    
                    if not intent_analysis:
                        logging.warning("í…ìŠ¤íŠ¸ íŒŒì‹±ë„ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ë°˜í™˜")
                        return text, self._get_default_intent_analysis(text)
                    
        except Exception as e:
            logging.error(f"í†µí•© í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            logging.error(f"í†µí•© ë¶„ì„ ì‹¤íŒ¨ ìƒì„¸: exception_type={type(e).__name__}, message={str(e)}")
            logging.error(f"í†µí•© ë¶„ì„ ì‹¤íŒ¨ ì»¨í…ìŠ¤íŠ¸: text='{text[:50]}...', model='{self.model}'")
            return text, self._get_default_intent_analysis(text)

    def _parse_text_response(self, response_text: str, original_text: str) -> Tuple[str, Dict]:
        """í…ìŠ¤íŠ¸ ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ ì˜ë„ ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ"""
        try:
            # ê¸°ë³¸ê°’ ì„¤ì •
            corrected_text = original_text
            intent_analysis = {
                "core_intent": "general_inquiry",
                "intent_category": "ì¼ë°˜ë¬¸ì˜",
                "primary_action": "ê¸°íƒ€",
                "target_object": "ê¸°íƒ€",
                "constraint_conditions": [],
                "standardized_query": original_text,
                "semantic_keywords": [original_text[:20]],
                "intent_type": "ì¼ë°˜ë¬¸ì˜",
                "main_topic": "ê¸°íƒ€",
                "specific_request": original_text[:100],
                "keywords": [original_text[:20]],
                "urgency": "medium",
                "action_type": "ê¸°íƒ€"
            }
            
            # í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œë„
            if "ì˜¤íƒ€" in response_text or "ìˆ˜ì •" in response_text:
                # ì˜¤íƒ€ ìˆ˜ì •ì´ ìˆëŠ” ê²½ìš°
                lines = response_text.split('\n')
                for line in lines:
                    if "ìˆ˜ì •ëœ" in line or "corrected" in line.lower():
                        corrected_text = line.split(':')[-1].strip() if ':' in line else line.strip()
                        break
            
            # ì˜ë„ ë¶„ì„ í‚¤ì›Œë“œ ì¶”ì¶œ
            if "ì˜ë„" in response_text or "intent" in response_text.lower():
                lines = response_text.split('\n')
                for line in lines:
                    if "í•µì‹¬" in line or "core" in line.lower():
                        intent_analysis["core_intent"] = line.split(':')[-1].strip() if ':' in line else "general_inquiry"
                    elif "í–‰ë™" in line or "action" in line.lower():
                        intent_analysis["primary_action"] = line.split(':')[-1].strip() if ':' in line else "ê¸°íƒ€"
                    elif "ëŒ€ìƒ" in line or "target" in line.lower():
                        intent_analysis["target_object"] = line.split(':')[-1].strip() if ':' in line else "ê¸°íƒ€"
            
            logging.info(f"í…ìŠ¤íŠ¸ íŒŒì‹± ê²°ê³¼ - ìˆ˜ì •ëœ í…ìŠ¤íŠ¸: '{corrected_text}'")
            logging.info(f"í…ìŠ¤íŠ¸ íŒŒì‹± ê²°ê³¼ - ì˜ë„ ë¶„ì„: {json.dumps(intent_analysis, ensure_ascii=False)}")
            
            return corrected_text, intent_analysis
            
        except Exception as e:
            logging.error(f"í…ìŠ¤íŠ¸ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return original_text, self._get_default_intent_analysis(original_text)
    
    def _get_default_intent_analysis(self, text: str) -> Dict:
        """ë¶„ì„ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ì˜ë„ ë¶„ì„ ê²°ê³¼"""
        return {
            "core_intent": "general_inquiry",
            "intent_category": "ì¼ë°˜ë¬¸ì˜",
            "primary_action": "ê¸°íƒ€",
            "target_object": "ê¸°íƒ€",
            "constraint_conditions": [],
            "standardized_query": text,
            "semantic_keywords": [text[:20]],
            # ê¸°ì¡´ í˜¸í™˜ì„± í•„ë“œ
            "intent_type": "ì¼ë°˜ë¬¸ì˜",
            "main_topic": "ê¸°íƒ€",
            "specific_request": text[:100],
            "keywords": [text[:20]],
            "urgency": "medium",
            "action_type": "ê¸°íƒ€"
        }
