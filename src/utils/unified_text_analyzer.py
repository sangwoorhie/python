#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
í†µí•© í…ìŠ¤íŠ¸ ë¶„ì„ê¸° ëª¨ë“ˆ
- ì˜¤íƒ€ ìˆ˜ì •ê³¼ ì˜ë„ ë¶„ì„ì„ í•œ ë²ˆì˜ GPT í˜¸ì¶œë¡œ ì²˜ë¦¬
- API ë¹„ìš© ì ˆê° ë° ì²˜ë¦¬ ì„±ëŠ¥ ìµœì í™”
"""

import logging
import json
from typing import Dict, Tuple
from src.utils.memory_manager import memory_cleanup

class UnifiedTextAnalyzer:
    """ì˜¤íƒ€ ìˆ˜ì • + ì˜ë„ ë¶„ì„ì„ í†µí•©í•œ ë¶„ì„ê¸°"""
    
    def __init__(self, openai_client):
        self.openai_client = openai_client
        self.model = 'gpt-5-mini'
    
    # í•œ ë²ˆì˜ GPT í˜¸ì¶œë¡œ ì˜¤íƒ€ ìˆ˜ì •ê³¼ ì˜ë„ ë¶„ì„ì„ ë™ì‹œì— ìˆ˜í–‰    
    # Args:
    #     text: ë¶„ì„í•  í…ìŠ¤íŠ¸
    # Returns:
    #     Tuple[str, Dict]: (ìˆ˜ì •ëœ_í…ìŠ¤íŠ¸, ì˜ë„_ë¶„ì„_ê²°ê³¼)
    def analyze_and_correct(self, text: str) -> Tuple[str, Dict]:

        try:
            with memory_cleanup():
                # í†µí•© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
                system_prompt = """ë‹¹ì‹ ì€ ë°”ì´ë¸” ì•± ë¬¸ì˜ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¤ìŒ ë‘ ê°€ì§€ ì‘ì—…ì„ ë™ì‹œì— ìˆ˜í–‰í•˜ì„¸ìš”:

1. ë§ì¶¤ë²• ë° ì˜¤íƒ€ ìˆ˜ì • (ì˜ë¯¸ì™€ ì–´ì¡°ëŠ” ìœ ì§€)
2. ì§ˆë¬¸ì˜ ë³¸ì§ˆì  ì˜ë„ ë¶„ì„

ì‘ë‹µ í˜•ì‹ (JSON):
{
    "corrected_text": "ì˜¤íƒ€ê°€ ìˆ˜ì •ëœ í…ìŠ¤íŠ¸",
    "intent_analysis": {
        "core_intent": "í•µì‹¬ ì˜ë„ (í‘œì¤€í™”ëœ í˜•íƒœ)",
        "intent_category": "ì˜ë„ ì¹´í…Œê³ ë¦¬",
        "primary_action": "ì£¼ìš” í–‰ë™",
        "target_object": "ëŒ€ìƒ ê°ì²´",
        "constraint_conditions": ["ì œì•½ ì¡°ê±´ë“¤"],
        "standardized_query": "í‘œì¤€í™”ëœ ì§ˆë¬¸ í˜•íƒœ",
        "semantic_keywords": ["ì˜ë¯¸ë¡ ì  í•µì‹¬ í‚¤ì›Œë“œë“¤"]
    }
}

ì˜¤íƒ€ ìˆ˜ì • ì§€ì¹¨:
- ì•±/ì–´í”Œë¦¬ì¼€ì´ì…˜ â†’ ì•±ìœ¼ë¡œ í†µì¼
- ë„ì–´ì“°ê¸°, ë§ì¶¤ë²•, ì¡°ì‚¬ ì‚¬ìš©ë²• ì •í™•íˆ êµì •
- ì›ë¬¸ì˜ ì˜ë¯¸ì™€ ì–´ì¡°ëŠ” ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€

ì˜ë„ ë¶„ì„ ì§€ì¹¨:
- ì§ˆë¬¸ì˜ ë³¸ì§ˆì  ëª©ì  íŒŒì•…
- êµ¬ì²´ì  ì˜ˆì‹œ ì œê±°í•˜ê³  ì¼ë°˜í™”
- ì˜ë¯¸ë¡ ì ìœ¼ë¡œ ë™ë“±í•œ ì§ˆë¬¸ë“¤ì´ ê°™ì€ ê²°ê³¼ ë„ì¶œí•˜ë„ë¡ ë¶„ì„"""

                user_prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n{text}"
                
                # GPT API í˜¸ì¶œ
                response = self.openai_client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    max_tokens=600,
                    temperature=0.1  # ì¼ê´€ì„± ì¤‘ì‹œ
                )
                
                result_text = response.choices[0].message.content.strip()
                
                try:
                    # JSON íŒŒì‹±
                    result = json.loads(result_text)
                    corrected_text = result.get('corrected_text', text)
                    intent_analysis = result.get('intent_analysis', {})
                    
                    # ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í•„ë“œ ì¶”ê°€
                    intent_analysis.update({
                        'intent_type': intent_analysis.get('intent_category', 'ì¼ë°˜ë¬¸ì˜'),
                        'main_topic': intent_analysis.get('target_object', 'ê¸°íƒ€'),
                        'specific_request': intent_analysis.get('standardized_query', text[:100]),
                        'keywords': intent_analysis.get('semantic_keywords', [text[:20]]),
                        'urgency': 'medium',
                        'action_type': intent_analysis.get('primary_action', 'ê¸°íƒ€')
                    })
                    
                    # ë¡œê¹…
                    if corrected_text != text:
                        logging.info(f"í†µí•© ë¶„ì„ - ì˜¤íƒ€ ìˆ˜ì •: '{text[:50]}...' â†’ '{corrected_text[:50]}...'")
                    
                    logging.info(f"í†µí•© ë¶„ì„ - ì˜ë„: {intent_analysis.get('core_intent', 'N/A')}")
                    # ğŸ” ë””ë²„ê·¸: GPT ì‘ë‹µ ì „ì²´ ì¶œë ¥
                    logging.info("="*60)
                    logging.info("ğŸ“Š [í†µí•© ë¶„ì„ ê²°ê³¼]")
                    logging.info(f"ì…ë ¥ í…ìŠ¤íŠ¸: {text}")
                    logging.info(f"GPT ì›ë³¸ ì‘ë‹µ: {result_text}")
                    logging.info("="*60)
                    
                    result = json.loads(result_text)
                    corrected_text = result.get('corrected_text', text)
                    intent_analysis = result.get('intent_analysis', {})
                    
                    # ğŸ” ë””ë²„ê·¸: íŒŒì‹±ëœ ê²°ê³¼ ì¶œë ¥
                    logging.info("ğŸ“ [íŒŒì‹± ê²°ê³¼]")
                    logging.info(f"ìˆ˜ì •ëœ í…ìŠ¤íŠ¸: {corrected_text}")
                    logging.info(f"ì˜ë„ ë¶„ì„: {json.dumps(intent_analysis, ensure_ascii=False, indent=2)}")
                    logging.info("="*60)
                    
                    return corrected_text, intent_analysis
                    
                except json.JSONDecodeError:
                    # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
                    logging.warning(f"í†µí•© ë¶„ì„ JSON íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ê°’ ë°˜í™˜: {result_text}")
                    return text, self._get_default_intent_analysis(text)
                
        except Exception as e:
            logging.error(f"í†µí•© í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return text, self._get_default_intent_analysis(text)
    
    def _get_default_intent_analysis(self, text: str) -> Dict:
        """ë¶„ì„ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ì˜ë„ ë¶„ì„ ê²°ê³¼"""
        return {
            "core_intent": "general_inquiry",
            "intent_category": "ì¼ë°˜ë¬¸ì˜",
            "primary_action": "ê¸°íƒ€",
            "target_object": "ê¸°íƒ€",
            "constraint_conditions": [],
            "standardized_query": text,
            "semantic_keywords": [text[:20]],
            # ê¸°ì¡´ í˜¸í™˜ì„± í•„ë“œ
            "intent_type": "ì¼ë°˜ë¬¸ì˜",
            "main_topic": "ê¸°íƒ€",
            "specific_request": text[:100],
            "keywords": [text[:20]],
            "urgency": "medium",
            "action_type": "ê¸°íƒ€"
        }
