<1.	검색결과 캐시>
-	비슷한 질문이면 캐시에서 가져오는지?
-	캐시관리가 어떻게 되는지?

현재는 정확히 동일한 질문만 캐시에서 가져오고, 의미적으로 비슷한 질문은 캐시를 활용하지 않는 상태.
100% 정확한 매칭만 가능:

"성경통독을하루에 최대 몇 장  할 수 있나요?" ← 공백 2개
"성경통독을하루에 최대 몇 장 할 수 있나요?" ← 공백 1개
결과: 서로 다른 캐시 키 → 별도 검색 수행

# 모든 캐시 키 목록 조회 (패턴별)
redis-cli keys "embedding:*"    # 임베딩 캐시
redis-cli keys "intent:*"       # 의도분석 캐시
redis-cli keys "typo:*"         # 오타수정 캐시
redis-cli keys "translation:*"  # 번역 캐시
redis-cli keys "search:*"       # 검색결과 캐시

다층 캐시 구조
Level 1: 검색 결과 캐시 (최상위) - 24시간 TTL
├── 키: "search:해시값"
├── 저장: 최종 검색 결과 (점수 계산 완료된 상태)
└── 로그: "검색 결과 캐시 저장: ... (3개 결과)"

Level 2: 임베딩 벡터 캐시 - 영구 보관
├── 키: 질문 텍스트 자체
├── 저장: 1536차원 벡터 데이터  
└── 로그: "임베딩 캐시 저장: ... (1536차원)"

Level 3: 의도 관련성 계산 캐시 - 메모리 (1000개 제한)
├── 키: "의도:참조질문" 조합
├── 저장: 의도 유사성 점수
└── 용도: 동일한 참조답변 재분석 방지

Level 4: API 응답 캐시 (Redis) - GPT 호출 결과
├── 키: 요청 해시
├── 저장: GPT 원본 응답
└── 용도: 동일한 API 호출 방지

3. 현재 로그의 캐시 동작
# 1단계: 검색 결과 캐시 확인
캐시 조회 시작: 검색 결과, 키=search:61099d1bcf3a8b40
검색 결과 캐시 전체 미스 - 새 검색 필요  ← 이전에 없던 질문

# 2단계: 임베딩 생성 및 캐시 저장  
임베딩 캐시 저장: 성경 통독을 하루에... (1536차원)  ← 새로 생성
임베딩 캐시 저장: 사용자가 하루에 성경... (1536차원)  ← 새로 생성  
임베딩 캐시 저장: 성경 성경 통독 하루... (1536차원)  ← 새로 생성

# 3단계: 검색 완료 후 결과 캐시 저장
검색 결과 캐시 저장: 성경 통독을 하루에... (3개 결과)  ← 다음에 재사용



<2.	의도 관련성 / 개념 관련성은 어떻게 계산되는지?>

final_score = (벡터 유사도 * 0.6) + (의도 관련성 * 0.25) + (개념 관련성 * 0.15)

- 벡터 유사도 (60%): 텍스트를 숫자 벡터로 변환한 후, 코사인 유사도 같은 수학적 방법으로 계산되는 기본 텍스트 유사도. (이 부분은 질문의 초점이 아니니 간단히 넘기고, 나머지 두 가지에 집중하겠습니다.)
- 의도 관련성 (25%): 사용자가 정말로 묻고 싶은 "의도"가 기존 답변과 얼마나 맞는지 측정.
- 개념 관련성 (15%): 질문에 포함된 핵심 개념(키워드나 아이디어)이 기존 답변과 얼마나 겹치는지 측정.

(예시) 사용자 질문: "요한복음 3장 16절 NIV하고 KJV 같이 보려면 어떻게 해야 하나요?"

기존 데이터베이스 답변들:
답변 A: "두 개의 번역본을 동시에 보는 방법은 화면 분할 기능을 사용하세요"
답변 B: "요한복음은 신약성경의 네 번째 책입니다"
답변 C: "NIV 번역본 설정 방법은 설정 메뉴에서 변경할 수 있습니다"


[1. 의도 관련성 로직]

- 순서 1. GPT가 사용자 질문 분석
사용자 질문: "요한복음 3장 16절 NIV하고 KJV 같이 보려면 어떻게 해야 하나요?"

GPT 분석 결과:
{
  "core_intent": "multiple_translations_view",      # 핵심 의도
  "primary_action": "보기",                         # 주요 행동
  "target_object": "번역본",                        # 대상 객체
  "semantic_keywords": ["동시에", "번역본", "비교"]  # 의미 키워드
}


- 순서 2. 기존 답변들 실시간 분석
답변 A 분석:
- 질문: "두 개의 번역본을 동시에 보는 방법은..."
- GPT 분석:
  - core_intent: "multiple_translations_view"  ✅ (사용자와 동일!)
  - primary_action: "보기"                     ✅
  - target_object: "번역본"                    ✅

답변 B 분석:
- 질문: "요한복음은 신약성경의..."
- GPT 분석:
  - core_intent: "bible_book_info"            ❌ (다른 의도)
  - primary_action: "설명"                    ❌
  - target_object: "성경책"                   ⚠️ (유사)

답변 C 분석:
- 질문: "NIV 번역본 설정 방법은..."
- GPT 분석:
  - core_intent: "translation_setting"        ⚠️ (부분 관련)
  - primary_action: "설정"                    ❌
  - target_object: "번역본"                   ✅


- 순서 3. 의도 점수 계산 (가중치 적용)
def calculate_intent_similarity():
    # 답변 A의 경우:
    intent_match = 1.0      # core_intent 완전 일치 (40%)
    action_match = 1.0      # "보기" == "보기" (25%)  
    object_match = 1.0      # "번역본" == "번역본" (20%)
    keyword_match = 0.67    # 2/3 키워드 일치 (15%)
    
    답변_A_점수 = (1.0 * 0.4) + (1.0 * 0.25) + (1.0 * 0.2) + (0.67 * 0.15)
               = 0.4 + 0.25 + 0.2 + 0.1 = 0.95
    
    # 답변 B의 경우:
    intent_match = 0.0      # 완전 다른 의도
    action_match = 0.0      # "보기" != "설명"
    object_match = 0.8      # "번역본" vs "성경책" (유사도 테이블)
    keyword_match = 0.0     # 키워드 불일치
    
    답변_B_점수 = 0 + 0 + (0.8 * 0.2) + 0 = 0.16


[2. 개념 관련성 로직]

- 순서 1. 핵심 개념 추출 (규칙 기반)
python사용자 질문에서 추출:
- "요한복음" (가중치: 0.4)
- "NIV" (가중치: 0.3)  
- "KJV" (가중치: 0.3)
- "동시에" (가중치: 0.5)

# 추출 규칙:
- 고유명사 (성경 이름, 번역본명)
- 핵심 동사/부사
- 3자 이상 명사

- 순서 2. 답변별 개념 매칭

답변 A의 개념: ["번역본", "동시에", "화면", "분할"]
매칭 결과:
- "동시에" ✅ (정확 일치) = 0.5 점
- "NIV", "KJV" ⚠️ (부분 일치 - "번역본"과 70% 유사) = 0.3 * 0.7 = 0.21
총점: (0.5 + 0.21) / 1.5 = 0.47

답변 B의 개념: ["요한복음", "신약", "성경"]  
매칭 결과:
- "요한복음" ✅ = 0.4 점
총점: 0.4 / 1.5 = 0.27

답변 C의 개념: ["NIV", "설정", "메뉴"]
매칭 결과:
- "NIV" ✅ = 0.3 점
총점: 0.3 / 1.5 = 0.20

- ☆ 최종점수 계산
# 벡터 유사도(60%) + 의도 관련성(25%) + 개념 관련성(15%)

답변 A:
- 벡터 유사도: 0.85 (Pinecone 검색 결과)
- 의도 관련성: 0.95 (GPT 분석 - 거의 완벽 일치)
- 개념 관련성: 0.47 (키워드 부분 일치)
최종 점수 = (0.85 * 0.6) + (0.95 * 0.25) + (0.47 * 0.15) = 0.818

답변 B:
- 벡터 유사도: 0.65
- 의도 관련성: 0.16 (의도 불일치)
- 개념 관련성: 0.27 (요한복음만 일치)
최종 점수 = (0.65 * 0.6) + (0.16 * 0.25) + (0.27 * 0.15) = 0.471

답변 C:
- 벡터 유사도: 0.70
- 의도 관련성: 0.35 (부분적 관련)
- 개념 관련성: 0.20 (NIV만 일치)
최종 점수 = (0.70 * 0.6) + (0.35 * 0.25) + (0.20 * 0.15) = 0.538

=> 답변 A가 선택될 확률이 높음.


<3.	5개 레이어를 구성한 이유와, 어떻게 사용되는지?>
다층 검색 시스템은 하나의 질문에 대해 다각도로 접근하여 놓칠 수 있는 관련 답변들을 최대한 찾아내는 전략입니다. 
각 레이어는 "서로 다른 방식"으로 의미적 유사성을 탐지하므로, 전체적으로 검색 품질과 커버리지를 크게 향상시킴.
동적 레이어 결정 로직으로 레이어 별 가중치를 달리 주며, 조건에 따라 모든 레이어가 활성화되지 않을 수 있습니다.

Layer 1: 원본 질문 (Original Query)
목적 : 사용자가 입력한 정확한 표현과 일치하는 답변 찾기

Layer 2: 표준화된 의도 기반 질문 (Intent-based Query)
목적 :  GPT가 분석한 표준화된 형태로 검색하여 의미적으로 동일한 다른 표현 매칭

Layer 3: 핵심 의도만 (Core Intent)
목적 : 질문의 본질적 의도를 추상화하여 더 넓은 범위의 관련 답변 찾기

Layer 4: 의미론적 키워드 조합 (Semantic Keywords)
목적 : GPT가 추출한 핵심 키워드로 검색하여 키워드 중심 매칭

Layer 5: 개념 기반 검색 (Concept-based)
목적 : 규칙 기반으로 추출한 개념들로 보완 검색 수행


<4.	의도 분석을 어떻게 하는지? 구성과 예시>
=> 로그에서 확인 가능.


<5.	점수를 매긴 다음 어떻게 유사답변을 가져오는지?>
검색 결과 후처리 및 최종 점수 계산 메서드인 => 
경로: src/services/optimized_search_service.py → def _postprocess_results 매서드

- 순서 1. 최종 점수 계산: 벡터(60%) + 의도(25%) + 개념(15%)
초기 검색 결과(search_results)를 입력받아 각 결과에 대해 세 가지 점수를 계산하고, 이를 조합해 최종 점수(final_score)를 매김.

# 최종 점수 = 벡터 유사도(60%) + 의도 관련성(25%) + 개념 관련성(15%)
            final_score = (adjusted_score * 0.6 + 
                        intent_relevance * 0.25 + 
                        concept_relevance * 0.15)

- 순서 2. 임계값 적용: 상위 3개는 0.3, 나머지는 동적 임계값
# 최소 임계값 또는 상위 순위 확인
            if final_score >= min_threshold or i < 3:
                print(f"✅ [SEARCH DEBUG] 결과 #{i+1} 선택됨: 최종점수={final_score:.3f} (임계값={min_threshold:.3f})")
                final_results.append({
                    'score': final_score,
                    'vector_score': vector_score,
                    'intent_relevance': intent_relevance,
                    'concept_relevance': concept_relevance,
                    'question': question,
                    'answer': answer,
                    'category': category,
                    'rank': i + 1,
                    'search_type': match['search_type'],
                    'layer_weight': match.get('layer_weight', 1.0),
                    'lang': 'ko'
                })

            # top_k 개수에 도달하면 중단
            if len(final_results) >= top_k:
                break

- 순서 3. 순차 선택
상위 3개 결과: 임계값 0.3 (더 관대한 기준)
4번째 이후: 동적 임계값 적용 (더 엄격한 기준)
최대 개수: top_k 개수만큼만 선택

- 순서 4. 동적 임계값 계산
scores = [r['score'] for r in search_results[:top_k*2]]
if len(scores) >= 4:
    scores.sort(reverse=True)
    top_percentile = scores[0] * 0.8
    bottom_percentile = scores[-1] * 1.2
    dynamic_threshold = (top_percentile + bottom_percentile) / 2
else:
    dynamic_threshold = 0.5

- 순서 5. 최종 결과 반환

(요약)
1. 점수 계산: 벡터(60%) + 의도(25%) + 개념(15%)
2. 임계값 적용: 상위 3개는 0.3, 나머지는 동적 임계값
3. 순차 선택: 점수 순으로 검토하여 임계값 통과시 선택
4. 개수 제한: top_k 개수에 도달하면 중단
5. 결과 반환: 선택된 유사답변들 반환

아래에서 로그 확인 가능.

vi /home/ec2-user/python/debug_search_results.txt


<6.	실행되는 전체 로그>


<7. 컨텍스트 품질 분석 메서드 >
경로: src>services>optimized_search_service.py → def analyze_context_quality

1단계: Excellent (우수)
조건: 최고 점수 0.9 이상 + 의도 관련성 0.7 이상
의미: 검색 결과가 거의 완벽하게 질문과 일치
처리: 검색된 답변을 그대로 사용 (GPT 재생성 불필요)

2단계: Very High (매우 높음)
조건: 최고 점수 0.8 이상 + 의도 관련성 0.6 이상
의미: 매우 높은 품질의 관련 결과
처리: 검색된 답변을 그대로 사용

3단계: High (높음)
조건: 최고 점수 0.7 이상 + 의도 관련성 0.5 이상
의미: 좋은 품질이지만 약간의 보완 필요
처리: GPT가 검색 결과를 참고하여 답변 재생성

4단계: Medium (보통)
조건: 최고 점수 0.6 이상 + 고품질/관련성 결과 2개 이상
의미: 여러 좋은 결과들이 있어 종합 가능
처리: GPT가 여러 검색 결과를 종합하여 답변 생성

5단계: Low (낮음)
조건: 최고 점수 0.4 이상 + 의도 관련성 0.4 이상
의미: 관련성은 있지만 품질이 낮음
처리: GPT가 제한적 정보로 답변 생성

6단계: Very Low (매우 낮음) / None (없음)
조건: 위 조건들을 모두 만족하지 않음
의미: 관련성 있는 결과가 거의 없음
처리: 기본 폴백 답변 제공


📈 실제 사용 예시
성도님이 "예수님의 십자가 고난에 대해 알려주세요"라고 질문했을 때:

시나리오 1: Excellent 품질
검색 결과:
- 결과 1: 점수 0.95, 의도 관련성 0.85 → "십자가 고난에 대한 상세한 설명"
- 결과 2: 점수 0.92, 의도 관련성 0.78 → "예수님의 수난사"
- 결과 3: 점수 0.89, 의도 관련성 0.75 → "십자가의 의미"

→ 품질: Excellent
→ 처리: 검색된 답변을 그대로 사용 (빠른 응답)


시나리오 2: High 품질
검색 결과:
- 결과 1: 점수 0.75, 의도 관련성 0.55 → "십자가에 대한 일반적 설명"
- 결과 2: 점수 0.72, 의도 관련성 0.52 → "예수님의 생애"
- 결과 3: 점수 0.68, 의도 관련성 0.48 → "기독교 교리"

→ 품질: High
→ 처리: GPT가 검색 결과를 참고하여 더 정확한 답변 생성


시나리오 3: Low 품질
검색 결과:
- 결과 1: 점수 0.45, 의도 관련성 0.42 → "일반적인 종교 이야기"
- 결과 2: 점수 0.41, 의도 관련성 0.38 → "역사적 사건들"
- 결과 3: 점수 0.38, 의도 관련성 0.35 → "기타 내용"

→ 품질: Low
→ 처리: GPT가 제한적 정보로 최선의 답변 시도

요약 : 
높은 품질: 빠른 직접 반환으로 응답 속도 최적화
중간 품질: GPT 재생성으로 답변 품질 향상
낮은 품질: 최소한의 관련성이라도 확보하여 사용자 만족도 유지