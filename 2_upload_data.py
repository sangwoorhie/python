import os
import pandas as pd
from dotenv import load_dotenv
from pinecone import Pinecone
import time
import re
from datetime import datetime
from openai import OpenAI
import html

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

# Pinecone ì´ˆê¸°í™” (3072ì°¨ì›ìš© ì¸ë±ìŠ¤)
pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))
index = pc.Index("bible-app-support-3072")

print("âœ“ OpenAI text-embedding-3-small ëª¨ë¸ ì‚¬ìš© ì¤€ë¹„ ì™„ë£Œ!")

def clean_html_text(text):
    """HTML íƒœê·¸ì™€ ì—”í‹°í‹°ë¥¼ ì œê±°í•˜ê³  ê¹¨ë—í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if not text or pd.isna(text):
        return ""
    
    text = str(text)
    
    # HTML ì—”í‹°í‹° ë””ì½”ë”© (&nbsp; â†’ ê³µë°±, &lt; â†’ < ë“±)
    text = html.unescape(text)
    
    # <br>, <p> íƒœê·¸ë¥¼ ì¤„ë°”ê¿ˆìœ¼ë¡œ ë³€í™˜
    text = re.sub(r'<br\s*/?>', '\n', text, flags=re.IGNORECASE)
    text = re.sub(r'</p>', '\n', text, flags=re.IGNORECASE)
    text = re.sub(r'<p[^>]*>', '\n', text, flags=re.IGNORECASE)
    
    # <li> íƒœê·¸ëŠ” ì•ì— "- " ì¶”ê°€
    text = re.sub(r'<li[^>]*>', '\n- ', text, flags=re.IGNORECASE)
    text = re.sub(r'</li>', '', text, flags=re.IGNORECASE)
    
    # <strong>, <b> íƒœê·¸ëŠ” ** ë¡œ ë³€í™˜ (ê°•ì¡° í‘œì‹œ)
    text = re.sub(r'<(strong|b)[^>]*>', '**', text, flags=re.IGNORECASE)
    text = re.sub(r'</(strong|b)>', '**', text, flags=re.IGNORECASE)
    
    # ê¸°íƒ€ ëª¨ë“  HTML íƒœê·¸ ì œê±°
    text = re.sub(r'<[^>]+>', '', text)
    
    # ì—°ì†ëœ ì¤„ë°”ê¿ˆì„ ì •ë¦¬ (3ê°œ ì´ìƒ â†’ 2ê°œ)
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    text = re.sub(r'[ \t]+', ' ', text)
    
    # ì¤„ì˜ ì•ë’¤ ê³µë°± ì œê±°
    lines = [line.strip() for line in text.split('\n')]
    text = '\n'.join(line for line in lines if line)
    
    return text.strip()

def preprocess_text(text):
    """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (HTML íƒœê·¸ ì œê±° í¬í•¨)"""
    if pd.isna(text):
        return ""
    
    # ë¬¸ìì—´ë¡œ ë³€í™˜
    text = str(text)
    
    # HTML íƒœê·¸ ì œê±° ë° ì •ë¦¬
    text = clean_html_text(text)
    
    # ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ë³€í™˜ (ì„ë² ë”©ì„ ìœ„í•´)
    text = text.replace('\n', ' ')
    
    # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    text = re.sub(r'\s+', ' ', text).strip()
    
    # ìµœëŒ€ ê¸¸ì´ ì œí•œ
    if len(text) > 8000:
        text = text[:8000]
    
    return text

def create_embedding(text, retry_count=3):
    """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ (OpenAI text-embedding-3-small ì‚¬ìš©)"""
    for attempt in range(retry_count):
        try:
            # OpenAI text-embedding-3-small ëª¨ë¸ ì‚¬ìš© (3,072ì°¨ì›)
            response = openai_client.embeddings.create(
                model="text-embedding-3-small",
                input=text,
                encoding_format="float"
            )
            embedding = response.data[0].embedding
            return embedding
        except Exception as e:
            print(f"  ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{retry_count}): {e}")
            if attempt < retry_count - 1:
                time.sleep(2 ** attempt)  # ì§€ìˆ˜ì  ë°±ì˜¤í”„
            else:
                return None

def categorize_question(question):
    """ì§ˆë¬¸ ìë™ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
    question_lower = question.lower()
    
    if any(word in question_lower for word in ['ì˜¤ë””ì˜¤', 'ìŒì„±', 'ì†Œë¦¬', 'ë“¤ë¦¬', 'ë…¹ìŒ']):
        return 'ì˜¤ë””ì˜¤'
    elif any(word in question_lower for word in ['ê²€ìƒ‰', 'ì°¾ê¸°', 'ì°¾ì„']):
        return 'ê²€ìƒ‰'
    elif any(word in question_lower for word in ['ë¡œê·¸ì¸', 'ë¹„ë°€ë²ˆí˜¸', 'ì•„ì´ë””', 'ê³„ì •', 'ê°€ì…']):
        return 'ê³„ì •'
    elif any(word in question_lower for word in ['êµ¬ë…', 'ê²°ì œ', 'ìš”ê¸ˆ', 'í™˜ë¶ˆ']):
        return 'êµ¬ë…'
    elif any(word in question_lower for word in ['ì˜¤ë¥˜', 'ì—ëŸ¬', 'ë²„ê·¸', 'ì¢…ë£Œ', 'ë©ˆì¶¤', 'ëŠë ¤']):
        return 'ì˜¤ë¥˜'
    elif any(word in question_lower for word in ['ì„¤ì •', 'ì•Œë¦¼', 'í‘¸ì‹œ']):
        return 'ì„¤ì •'
    elif any(word in question_lower for word in ['í†µë…', 'ì½ê¸°', 'ì„±ê²½']):
        return 'ì„±ê²½'
    else:
        return 'ì¼ë°˜'

def upload_bible_data(batch_size=20, max_items=None):
    """data_100.csv íŒŒì¼ì„ Pineconeì— ì—…ë¡œë“œ (HTML íƒœê·¸ ì œê±° í¬í•¨)"""
    
    print("=" * 60)
    print("ë°”ì´ë¸” ì• í”Œ ìƒ˜í”Œ ë°ì´í„° ì—…ë¡œë“œ ì‹œì‘ (data_100.csv)")
    print("HTML íƒœê·¸ ì œê±° ë° í…ìŠ¤íŠ¸ ì •ë¦¬ í¬í•¨")
    print("=" * 60)
    
    # ë°ì´í„° ì½ê¸° - data_100.csvë¡œ ë³€ê²½
    print("\nğŸ“– 'data_100.csv' íŒŒì¼ ì½ëŠ” ì¤‘...")
    try:
        # ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„
        encodings = ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr']
        df = None
        
        for encoding in encodings:
            try:
                df = pd.read_csv('data_100.csv', encoding=encoding)  # íŒŒì¼ëª… ë³€ê²½
                print(f"âœ“ ì¸ì½”ë”© '{encoding}'ìœ¼ë¡œ íŒŒì¼ ì½ê¸° ì„±ê³µ")
                break
            except:
                continue
        
        if df is None:
            raise Exception("data_100.csv íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return
    
    print(f"âœ“ ì´ {len(df)}ê°œ ë°ì´í„° ë°œê²¬")
    
    # ì»¬ëŸ¼ëª… í™•ì¸
    print(f"âœ“ ì»¬ëŸ¼: {df.columns.tolist()}")
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    print("\nğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘ (HTML íƒœê·¸ ì œê±°)...")
    
    # ì „ì²˜ë¦¬ ì „ ìƒ˜í”Œ ì¶œë ¥
    if not df.empty:
        print("\nğŸ“ ì „ì²˜ë¦¬ ì „ ìƒ˜í”Œ:")
        sample_reply = df['reply_contents'].iloc[0]
        print(f"ì›ë³¸: {sample_reply[:150]}...")
        
        # ì „ì²˜ë¦¬ ì ìš©
        df['contents'] = df['contents'].apply(preprocess_text)
        df['reply_contents'] = df['reply_contents'].apply(preprocess_text)
        
        print("\nğŸ“ ì „ì²˜ë¦¬ í›„ ìƒ˜í”Œ:")
        cleaned_reply = df['reply_contents'].iloc[0]
        print(f"ì •ë¦¬ë¨: {cleaned_reply[:150]}...")
    
    # ë¹ˆ ê°’ ì œê±°
    df = df[(df['contents'] != '') & (df['reply_contents'] != '')]
    
    # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë°ì´í„° ì œí•œ
    if max_items and len(df) > max_items:
        df = df.head(max_items)
        print(f"âœ“ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ {max_items}ê°œë¡œ ì œí•œ")
    
    print(f"âœ“ ìœ íš¨í•œ ë°ì´í„°: {len(df)}ê°œ")
    
    # ì—…ë¡œë“œ ì‹œì‘
    print(f"\nğŸ“¤ Pinecone ì—…ë¡œë“œ ì‹œì‘...")
    print(f"ë°°ì¹˜ í¬ê¸°: {batch_size}ê°œ")
    
    vectors_to_upsert = []
    success_count = 0
    failed_count = 0
    start_time = datetime.now()
    
    for idx, row in df.iterrows():
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        if idx % 10 == 0:
            elapsed_time = (datetime.now() - start_time).total_seconds()
            if idx > 0:
                avg_time_per_item = elapsed_time / idx
                remaining_items = len(df) - idx
                estimated_remaining = avg_time_per_item * remaining_items
                print(f"\nì§„í–‰: {idx}/{len(df)} ({idx/len(df)*100:.1f}%) | "
                      f"ì„±ê³µ: {success_count} | ì‹¤íŒ¨: {failed_count} | "
                      f"ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {estimated_remaining/60:.1f}ë¶„")
        
        # ì§ˆë¬¸ ë²¡í„°í™” (OpenAI ì‚¬ìš©)
        embedding = create_embedding(row['contents'])
        
        if embedding is None:
            failed_count += 1
            continue
        
        # ì¹´í…Œê³ ë¦¬ ìë™ ë¶„ë¥˜
        category = categorize_question(row['contents'])
        
        # ë©”íƒ€ë°ì´í„° êµ¬ì„±
        metadata = {
            "seq": int(row['seq']),
            "question": row['contents'][:1000],  # ë©”íƒ€ë°ì´í„° í¬ê¸° ì œí•œ
            "answer": row['reply_contents'][:1000],  # ë©”íƒ€ë°ì´í„° í¬ê¸° ì œí•œ
            "category": category,
            "source": "data_100_sample_clean"
        }
        
        # ê³ ìœ  ID ìƒì„± (seq ì‚¬ìš©)
        unique_id = f"qa_sample100_{row['seq']}"
        
        # ë²¡í„° ë°ì´í„° êµ¬ì„±
        vectors_to_upsert.append({
            "id": unique_id,
            "values": embedding,
            "metadata": metadata
        })
        
        # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ ì—…ë¡œë“œ
        if len(vectors_to_upsert) >= batch_size:
            try:
                index.upsert(vectors=vectors_to_upsert)
                success_count += len(vectors_to_upsert)
                print(f"  âœ“ {len(vectors_to_upsert)}ê°œ ë²¡í„° ì—…ë¡œë“œ ì™„ë£Œ")
                vectors_to_upsert = []
                time.sleep(1)  # API ì œí•œ ë°©ì§€
            except Exception as e:
                print(f"  âŒ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
                failed_count += len(vectors_to_upsert)
                vectors_to_upsert = []
    
    # ë‚¨ì€ ë²¡í„° ì—…ë¡œë“œ
    if vectors_to_upsert:
        try:
            index.upsert(vectors=vectors_to_upsert)
            success_count += len(vectors_to_upsert)
            print(f"  âœ“ ë§ˆì§€ë§‰ {len(vectors_to_upsert)}ê°œ ë²¡í„° ì—…ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"  âŒ ë§ˆì§€ë§‰ ë°°ì¹˜ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
            failed_count += len(vectors_to_upsert)
    
    # ìµœì¢… í†µê³„
    total_time = (datetime.now() - start_time).total_seconds()
    print("\n" + "=" * 60)
    print("ğŸ“Š ì—…ë¡œë“œ ì™„ë£Œ í†µê³„")
    print("=" * 60)
    print(f"âœ“ ì„±ê³µ: {success_count}ê°œ")
    print(f"âœ— ì‹¤íŒ¨: {failed_count}ê°œ")
    print(f"â± ì´ ì†Œìš” ì‹œê°„: {total_time/60:.1f}ë¶„")
    print(f"ğŸ’¾ í‰ê·  ì²˜ë¦¬ ì†ë„: {success_count/(total_time/60):.1f}ê°œ/ë¶„")
    
    # Pinecone ì¸ë±ìŠ¤ í†µê³„
    print("\nğŸ“ˆ Pinecone ì¸ë±ìŠ¤ ìƒíƒœ:")
    stats = index.describe_index_stats()
    print(f"ì´ ë²¡í„° ìˆ˜: {stats['total_vector_count']}")
    
    print("\nâœ… data_100.csv ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("ğŸ“ HTML íƒœê·¸ê°€ ëª¨ë‘ ì œê±°ë˜ê³  ê¹¨ë—í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    # í™•ì¸ ë©”ì‹œì§€
    print("ë°”ì´ë¸” ì• í”Œ ìƒ˜í”Œ ë°ì´í„° ì—…ë¡œë“œë¥¼ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
    print(f"íŒŒì¼: data_100.csv (ì´ {len(pd.read_csv('data_100.csv'))}ê°œ ë°ì´í„°)")
    print(f"HTML íƒœê·¸ ì œê±° ë° í…ìŠ¤íŠ¸ ì •ë¦¬ í¬í•¨")
    print(f"ëª¨ë¸: OpenAI text-embedding-3-small (3,072ì°¨ì›)")
    print(f"ì˜ˆìƒ ì‹œê°„: ì•½ 5-10ë¶„")
    print(f"ë¹„ìš©: OpenAI API ì‚¬ìš© (ì†ŒëŸ‰ ìš”ê¸ˆ ë°œìƒ)")
    print("\nê³„ì†í•˜ë ¤ë©´ Enter, ì·¨ì†Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”...")
    input()
    
    # ì—…ë¡œë“œ ì‹¤í–‰
    upload_bible_data(batch_size=20, max_items=None)
