#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
=== ìµœì í™”ëœ AI ë‹µë³€ ìƒì„± Flask API ì„œë²„ ===
íŒŒì¼ëª…: free_4_ai_answer_generator_optimized.py
ëª©ì : Redis ìºì‹±, ë°°ì¹˜ ì²˜ë¦¬, ì§€ëŠ¥í˜• API ê´€ë¦¬ë¥¼ í†µí•©í•œ ê³ ì„±ëŠ¥ AI ë‹µë³€ ìƒì„± ì‹œìŠ¤í…œ

í•µì‹¬ ìµœì í™” ê¸°ëŠ¥:
- Redis ê¸°ë°˜ ì§€ëŠ¥í˜• ìºì‹± ì‹œìŠ¤í…œ
- ì—¬ëŸ¬ API í˜¸ì¶œì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•˜ëŠ” ì‹œìŠ¤í…œ
- ì¡°ê±´ë¶€ API í˜¸ì¶œ ë°©ì§€ í”„ë¡œì„¸ì„œ
- ë™ì  ê²€ìƒ‰ ë ˆì´ì–´ ì¡°ì •
- API í˜¸ì¶œ íšŸìˆ˜ 6-12íšŒ â†’ 2-4íšŒë¡œ íšê¸°ì  ê°ì†Œ

ê¸°ì¡´ ì½”ë“œì™€ì˜ ì™„ì „í•œ í˜¸í™˜ì„± ìœ ì§€:
- ë™ì¼í•œ API ì—”ë“œí¬ì¸íŠ¸
- ë™ì¼í•œ ì…ì¶œë ¥ í˜•ì‹
- ë™ì¼í•œ ê¸°ëŠ¥
"""

# ==================================================
# 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ êµ¬ê°„
# ==================================================
import os
import sys
import gc
import logging
import tracemalloc
from typing import Optional, Dict, Any

# ì›¹ í”„ë ˆì„ì›Œí¬ ê´€ë ¨
from flask import Flask

# AI ë° ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨
from pinecone import Pinecone
import openai
import pyodbc

# í™˜ê²½ì„¤ì • ë° ìœ í‹¸ë¦¬í‹°
from dotenv import load_dotenv

# ìµœì í™”ëœ ëª¨ë“ˆë“¤ import
from src.main_optimized_ai_generator import OptimizedAIAnswerGenerator
from src.services.sync_service import SyncService
from src.api.endpoints import create_endpoints

# ==================================================
# 2. ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ì„¤ì •
# ==================================================
# ë©”ëª¨ë¦¬ ì¶”ì  ì‹œì‘
tracemalloc.start()

# Flask ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
app = Flask(__name__)

# ==================================================
# 3. ë¡œê¹… ì‹œìŠ¤í…œ ì„¤ì • (ì½˜ì†” + íŒŒì¼)
# ==================================================
logger = logging.getLogger()
logger.setLevel(logging.INFO)

formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

# íŒŒì¼ í•¸ë“¤ëŸ¬
try:
    os.makedirs('/home/ec2-user/python/logs', exist_ok=True)
    file_handler = logging.FileHandler('/home/ec2-user/python/logs/ai_generator_optimized.log', encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
except Exception as e:
    print(f"ë¡œê·¸ íŒŒì¼ í•¸ë“¤ëŸ¬ ìƒì„± ì‹¤íŒ¨: {e}")

# ì½˜ì†” í•¸ë“¤ëŸ¬
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)

# ==================================================
# 4. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ë° ì‹œìŠ¤í…œ ìƒìˆ˜ ì •ì˜
# ==================================================
load_dotenv()

# AI ì„ë² ë”© ëª¨ë¸ ë° ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ìƒìˆ˜ë“¤
MODEL_NAME = 'text-embedding-3-small'
INDEX_NAME = "bible-app-support-1536-openai"
EMBEDDING_DIMENSION = 1536
MAX_TEXT_LENGTH = 8000

# GPT ìì—°ì–´ ëª¨ë¸ ì„¤ì •
GPT_MODEL = 'gpt-3.5-turbo'
MAX_TOKENS = 600
TEMPERATURE = 0.5

# Redis ìºì‹± ì„¤ì •
REDIS_CONFIG = {
    'host': os.getenv('REDIS_HOST', 'localhost'),
    'port': int(os.getenv('REDIS_PORT', 6379)),
    'db': int(os.getenv('REDIS_DB', 0)),
    'password': os.getenv('REDIS_PASSWORD')
}

# ê³ ê° ë¬¸ì˜ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ í…Œì´ë¸”
CATEGORY_MAPPING = {
    '1': 'í›„ì›/í•´ì§€',
    '2': 'ì„±ê²½ í†µë…(ì½ê¸°,ë“£ê¸°,ë…¹ìŒ)',
    '3': 'ì„±ê²½ë‚­ë… ë ˆì´ìŠ¤',
    '4': 'ê°œì„ /ì œì•ˆ',
    '5': 'ì˜¤ë¥˜/ì¥ì• ',
    '6': 'ë¶ˆë§Œ',
    '7': 'ì˜¤íƒˆìì œë³´',
    '0': 'ì‚¬ìš© ë¬¸ì˜(ê¸°íƒ€)'
}

# ==================================================
# 5. ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ê²° ë° ì´ˆê¸°í™”
# ==================================================
try:
    # Pinecone ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •
    pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))
    index = pc.Index(INDEX_NAME)

    # OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    openai_client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

    # MSSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •
    mssql_config = {
        'server': os.getenv('MSSQL_SERVER'),
        'database': os.getenv('MSSQL_DATABASE'),
        'username': os.getenv('MSSQL_USERNAME'),
        'password': os.getenv('MSSQL_PASSWORD')
    }

    # MSSQL Server ì—°ê²° ë¬¸ìì—´ êµ¬ì„±
    connection_string = (
            f"DRIVER={{ODBC Driver 17 for SQL Server}};"
            f"SERVER={mssql_config['server']},1433;"
            f"DATABASE={mssql_config['database']};"
            f"UID={mssql_config['username']};"
            f"PWD={mssql_config['password']};"
            f"TrustServerCertificate=yes;"
            f"Connection Timeout=30;"
    )

except Exception as e:
    logging.error(f"ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {str(e)}")
    raise

# ==================================================
# 6. ìµœì í™”ëœ AI ë‹µë³€ ìƒì„±ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
# ==================================================

# ë©”ì¸ AI ë‹µë³€ ìƒì„±ê¸° (ìµœì í™”ëœ ì‹œìŠ¤í…œ)
generator = OptimizedAIAnswerGenerator(
    pinecone_index=index,
    openai_client=openai_client,
    connection_string=connection_string,
    category_mapping=CATEGORY_MAPPING,
    redis_config=REDIS_CONFIG
)

# í”„ë¡œë•ì…˜ ìµœì í™” ì„¤ì • ì ìš©
generator.optimize_for_production()

# ë™ê¸°í™” ë§¤ë‹ˆì € (ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•´ ë³„ë„ ì¸ìŠ¤í„´ìŠ¤ ìœ ì§€)
sync_manager = SyncService(
    pinecone_index=index,
    openai_client=openai_client,
    connection_string=connection_string,
    category_mapping=CATEGORY_MAPPING
)

# ==================================================
# 7. API ì—”ë“œí¬ì¸íŠ¸ ë“±ë¡
# ==================================================

# ëª¨ë“  ì—”ë“œí¬ì¸íŠ¸ë¥¼ ëª¨ë“ˆí™”ëœ endpoints.pyì—ì„œ ë“±ë¡
app = create_endpoints(app, generator, sync_manager, index)


# ==================================================
# 8. ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì²˜ë¦¬
# ==================================================

@app.teardown_appcontext
def cleanup_request(exception=None):
    """ìš”ì²­ ì¢…ë£Œì‹œ ì •ë¦¬"""
    if exception:
        logging.error(f"ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {exception}")


def cleanup_on_exit():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œì‹œ ì •ë¦¬"""
    try:
        logging.info("ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì¤‘...")
        if 'generator' in globals():
            generator.cleanup()
        logging.info("ì •ë¦¬ ì™„ë£Œ")
    except Exception as e:
        logging.error(f"ì¢…ë£Œ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")


import atexit
atexit.register(cleanup_on_exit)

# ==================================================
# 9. ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
# ==================================================
if __name__ == "__main__":

    # í™˜ê²½ë³€ìˆ˜ì—ì„œ í¬íŠ¸ ì„¤ì • ë¡œë“œ (ê¸°ë³¸ê°’: 8000)
    port = int(os.getenv('FLASK_PORT', 8000))

    # ì‹œì‘ ë©”ì‹œì§€ ì¶œë ¥
    print("="*80)
    print("ğŸš€ GOODTV ë°”ì´ë¸” ì• í”Œ AI ë‹µë³€ ìƒì„± ì„œë²„ (ìµœì í™”ëœ ë²„ì „)")
    print("="*80)
    print(f"ğŸ“¡ ì„œë²„ í¬íŠ¸: {port}")
    print(f"ğŸ¤– AI ëª¨ë¸: {GPT_MODEL} (Enhanced Context Mode)")
    print(f"ğŸ” ì„ë² ë”© ëª¨ë¸: {MODEL_NAME}")
    print(f"ğŸ—ƒï¸  ë²¡í„° DB: Pinecone ({INDEX_NAME})")
    print(f"ğŸ’¾ ìºì‹± ì‹œìŠ¤í…œ: Redis ({REDIS_CONFIG['host']}:{REDIS_CONFIG['port']})")
    print(f"ğŸŒ ë‹¤êµ­ì–´ ì§€ì›: í•œêµ­ì–´(ko), ì˜ì–´(en)")
    print("")
    print("ğŸ”§ ì œê³µ ì„œë¹„ìŠ¤:")
    print("   â”œâ”€â”€ AI ë‹µë³€ ìƒì„± (/generate_answer)")
    print("   â”œâ”€â”€ Pinecone ë™ê¸°í™” (/sync_to_pinecone)")
    print("   â”œâ”€â”€ í—¬ìŠ¤ì²´í¬ (/health)")
    print("   â”œâ”€â”€ ìµœì í™” í†µê³„ (/optimization/stats)")
    print("   â”œâ”€â”€ ìºì‹œ ê´€ë¦¬ (/optimization/cache/clear)")
    print("   â””â”€â”€ ì„¤ì • ê´€ë¦¬ (/optimization/config)")
    print("   ğŸ“ ëª¨ë“  ì—”ë“œí¬ì¸íŠ¸ëŠ” src/api/endpoints.pyì—ì„œ ëª¨ë“ˆí™” ê´€ë¦¬")
    print("")
    print("âš¡ í•µì‹¬ ìµœì í™” ê¸°ëŠ¥:")
    print("   â”œâ”€â”€ Redis ê¸°ë°˜ ì§€ëŠ¥í˜• ìºì‹± ì‹œìŠ¤í…œ")
    print("   â”œâ”€â”€ ì—¬ëŸ¬ API í˜¸ì¶œì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬")
    print("   â”œâ”€â”€ ì¡°ê±´ë¶€ API í˜¸ì¶œ ë°©ì§€ í”„ë¡œì„¸ì„œ")
    print("   â”œâ”€â”€ ë™ì  ê²€ìƒ‰ ë ˆì´ì–´ ì¡°ì •")
    print("   â”œâ”€â”€ API í˜¸ì¶œ íšŸìˆ˜: 6-12íšŒ â†’ 2-4íšŒë¡œ íšê¸°ì  ê°ì†Œ")
    print("   â”œâ”€â”€ ì‘ë‹µ ì‹œê°„: í‰ê·  50-70% ë‹¨ì¶•")
    print("   â””â”€â”€ API ë¹„ìš©: 60-80% ì ˆê°")
    print("")
    print("ğŸ”’ ê¸°ì¡´ í˜¸í™˜ì„±:")
    print("   â”œâ”€â”€ ë™ì¼í•œ API ì—”ë“œí¬ì¸íŠ¸")
    print("   â”œâ”€â”€ ë™ì¼í•œ ì…ì¶œë ¥ í˜•ì‹")
    print("   â”œâ”€â”€ ë™ì¼í•œ ê¸°ëŠ¥")
    print("   â””â”€â”€ ë¬´ì¤‘ë‹¨ ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ëŠ¥")
    print("="*80)
    
    # ìºì‹œ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    cache_available = generator.cache_manager.is_cache_available()
    cache_stats = generator.cache_manager.get_cache_stats()
    print(f"ğŸ’¾ ìºì‹± ì‹œìŠ¤í…œ: {'âœ… ì—°ê²°ë¨' if cache_available else 'âŒ ì—°ê²° ì‹¤íŒ¨'}")
    print(f"   â””â”€â”€ íƒ€ì…: {cache_stats.get('cache_type', 'Unknown')}")
    
    # ë°°ì¹˜ í”„ë¡œì„¸ì„œ ìƒíƒœ í™•ì¸
    batch_running = generator.batch_processor.running
    print(f"âš¡ ë°°ì¹˜ í”„ë¡œì„¸ì„œ: {'âœ… ì‹¤í–‰ ì¤‘' if batch_running else 'âŒ ì¤‘ì§€ë¨'}")
    
    # API ë§¤ë‹ˆì € ìƒíƒœ í™•ì¸
    api_health = generator.api_manager.health_check()
    print(f"ğŸ§  API ê´€ë¦¬ì: {'âœ… ì •ìƒ' if api_health['openai_client_available'] else 'âŒ ì˜¤ë¥˜'}")
    
    print("="*80)
    print("ğŸ¯ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ! API ìš”ì²­ì„ ë°›ì„ ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("="*80)

    # Flask ì›¹ ì„œë²„ ì‹œì‘
    app.run(host='0.0.0.0', port=port, debug=False, threaded=True)
